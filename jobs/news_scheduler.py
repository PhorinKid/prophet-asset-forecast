import requests
import pandas as pd
from sqlalchemy import create_engine, Column, Integer, String, Date, Text, Float, TIMESTAMP, ForeignKey, func, text
from sqlalchemy.orm import declarative_base, sessionmaker
from bs4 import BeautifulSoup
import openai
import time
import json
from datetime import datetime
import config
from apscheduler.schedulers.blocking import BlockingScheduler
import os
import sys

try:
    # 1. ë¡œì»¬ í™˜ê²½: config.pyê°€ ê°™ì€ í´ë”ì— ìˆë‹¤ë©´ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
    import config
    print("âœ… ë¡œì»¬ ì„¤ì • íŒŒì¼(config.py)ì„ ë°œê²¬í•˜ê³  ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    
    DB_CONFIG = config.DB_CONFIG
    LOSTARK_API_TOKEN = config.LOSTARK_API_TOKEN
    OPENAI_API_KEY = config.OPENAI_API_KEY
    TARGET_CATEGORIES = config.TARGET_CATEGORIES

except ImportError:
    # 2. ë„ì»¤/EC2 í™˜ê²½: config.pyê°€ ì—†ìœ¼ë¯€ë¡œ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì§ì ‘ ë§Œë“­ë‹ˆë‹¤.
    print("âš ï¸ config.pyê°€ ì—†ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜ë¥¼ ì§ì ‘ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    # .env íŒŒì¼ì—ì„œ ì½ì–´ì˜¨ ê°’ë“¤ì„ ì‚¬ìš©
    DB_CONFIG = {
        "host": os.getenv("DB_HOST"),
        "port": int(os.getenv("DB_PORT", 3306)), # ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 3306
        "user": os.getenv("DB_USER", "admin"),   # config.pyì— ìˆë˜ í•˜ë“œì½”ë”© ê°’ ë°˜ì˜
        "password": os.getenv("DB_PASSWORD"),
        "db": os.getenv("DB_NAME", "projectl")   # config.pyì— ìˆë˜ í•˜ë“œì½”ë”© ê°’ ë°˜ì˜
    }
    
    LOSTARK_API_TOKEN = os.getenv("LOSTARK_API_TOKEN")
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    
    # ì¹´í…Œê³ ë¦¬ëŠ” ë³´í†µ ì½¤ë§ˆ(,)ë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ë¡œ ê´€ë¦¬í•˜ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©
    # ë„ì»¤ ì‹¤í–‰ ì‹œ TARGET_CATEGORIES í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’([50000, 60000, 40000]) ì‚¬ìš©
    cats_env = os.getenv("TARGET_CATEGORIES")
    if cats_env:
        TARGET_CATEGORIES = [int(x.strip()) for x in cats_env.split(',')]
    else:
        TARGET_CATEGORIES = [50000, 60000, 40000] # í¬ë¦°ë‹˜ config íŒŒì¼ì˜ ê¸°ë³¸ê°’

# ==============================================================================
# [2] ì´ˆê¸°í™”
# ==============================================================================

db_url = f'mysql+pymysql://{DB_CONFIG["user"]}:{DB_CONFIG["password"]}@{DB_CONFIG["host"]}:{DB_CONFIG["port"]}/{DB_CONFIG["db"]}'
engine = create_engine(db_url)
Session = sessionmaker(bind=engine)
Base = declarative_base()

class RawNotice(Base):
    __tablename__ = 'raw_notices'
    id = Column(Integer, primary_key=True, autoincrement=True)
    notice_date = Column(Date, nullable=False)
    title = Column(String(255), nullable=False)
    link = Column(String(500), nullable=False)
    content = Column(Text, nullable=True)
    created_at = Column(TIMESTAMP, server_default=func.now())

class ItemNoticeImpact(Base):
    __tablename__ = 'item_notice_impacts'
    id = Column(Integer, primary_key=True, autoincrement=True)
    notice_id = Column(Integer, ForeignKey('raw_notices.id'), nullable=False)
    item_id = Column(Integer, nullable=False)
    gpt_score = Column(Float, default=0.0)
    demand_pressure = Column(Float, default=0.0)
    supply_pressure = Column(Float, default=0.0)
    behavior_pressure = Column(Float, default=0.0)
    impact_days = Column(Integer, default=0)
    analyzed_at = Column(TIMESTAMP, server_default=func.now())

client = openai.OpenAI(api_key=OPENAI_API_KEY)

# ==============================================================================
# [3] ë¡œì§
# ==============================================================================

def scrape_notice_content(url):
    """ ë³¸ë¬¸ ì „ì²´ ìˆ˜ì§‘ (60,000ì) """
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            content_div = soup.find('div', class_='fr-view')
            if not content_div:
                content_div = soup.find('div', class_='article-content')
            
            if content_div:
                text = content_div.get_text(separator='\n')
                clean_text = '\n'.join([line.strip() for line in text.splitlines() if line.strip()])
                return clean_text[:60000]
        return ""
    except Exception as e:
        print(f"í¬ë¡¤ë§ ì—ëŸ¬: {e}")
        return ""

def get_gpt_score(title, content, item_name):
    # [Expert ML Signal Prompt] ì›ë³¸ í”„ë¡¬í”„íŠ¸ ì ìš©
    prompt = f"""
    You are an economic signal generator for a time-series prediction model.

    Your task is NOT to summarize patch notes,
    but to convert game announcements into quantitative market signals
    that can be used as exogenous variables in ML/DL models.

    Target item: {item_name}

    Time horizon:
    - Short-term impact only (1 to 7 days)
    - Ignore long-term meta effects

    Based on the announcement below, estimate the following signals:

    1. Demand pressure on the item
    2. Supply pressure on the item
    3. Behavioral / sentiment pressure (panic buy, sell-off, hoarding)

    Scoring rules:
    - Each signal must be a float between -1.0 and 1.0
    - Positive = price upward pressure
    - Negative = price downward pressure
    - 0.0 = no meaningful impact

    If the announcement is mainly bug fixes or maintenance:
    - All signals must be 0.0

    Also estimate:
    4. Impact duration (number of days, integer 0â€“7)

    Announcement title:
    {title}

    Announcement content:
    {content[:60000]}

    Output JSON ONLY in the following format:
    {{
        "demand_pressure": <float>,
        "supply_pressure": <float>,
        "behavior_pressure": <float>,
        "impact_days": <int>,
        "total_score": <float>,
        "reason": "brief causal explanation (Must be written in KOREAN)"
    }}

    Rules:
    - total_score must be a weighted result of the three pressures
    - Do NOT speculate beyond the announcement text
    - If uncertain, reduce magnitude toward 0
    - IMPORTANT: The 'reason' field MUST be written in Korean.
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0
        )
        clean_json = response.choices[0].message.content.strip().replace("```json", "").replace("```", "")
        return json.loads(clean_json)
    except Exception as e:
        print(f"GPT Error: {e}")
        return {
            "demand_pressure": 0.0, "supply_pressure": 0.0, "behavior_pressure": 0.0,
            "impact_days": 0, "total_score": 0.0, "reason": "Error"
        }

def run_scheduler():
    print(f"\n[Scheduler Job Started] {datetime.now()}")
    session = Session()

    try:
        api_url = 'https://developer-lostark.game.onstove.com/news/notices?type=ê³µì§€&searchText=ì—…ë°ì´íŠ¸'
        headers = {'authorization': f'bearer {LOSTARK_API_TOKEN}'}
        res = requests.get(api_url, headers=headers)
        
        if res.status_code != 200:
            print("API í˜¸ì¶œ ì‹¤íŒ¨")
            return

        notices = res.json()
        target_notices = notices[:3]

        for notice_data in target_notices:
            n_date = pd.to_datetime(notice_data['Date']).date()
            n_title = notice_data['Title']
            n_link = notice_data['Link']

            existing = session.query(RawNotice).filter_by(title=n_title, notice_date=n_date).first()
            notice_id = None
            content_text = ""

            if not existing:
                print(f"ì‹ ê·œ ê³µì§€: {n_title}")
                content_text = scrape_notice_content(n_link)
                new_notice = RawNotice(notice_date=n_date, title=n_title, link=n_link, content=content_text)
                session.add(new_notice)
                session.commit()
                notice_id = new_notice.id
            else:
                print(f"ê¸°ì¡´ ê³µì§€: {n_title}")
                notice_id = existing.id
                content_text = existing.content

            # ì•„ì´í…œ ë¶„ì„
            items_sql = text("SELECT id, name FROM market_items WHERE category_code IN :cats")
            target_items = session.execute(items_sql, {"cats": tuple(TARGET_CATEGORIES)}).fetchall()

            print(f"-- ì•„ì´í…œ {len(target_items)}ê°œ ë¶„ì„ ì²´í¬...")
            
            analyze_count = 0
            for row in target_items:
                item_id = row[0]
                item_name = row[1]

                score_exists = session.query(ItemNoticeImpact).filter_by(notice_id=notice_id, item_id=item_id).first()
                
                if not score_exists:
                    result = get_gpt_score(n_title, content_text, item_name)
                    
                    impact = ItemNoticeImpact(
                        notice_id=notice_id,
                        item_id=item_id,
                        gpt_score=result['total_score'],
                        demand_pressure=result['demand_pressure'],
                        supply_pressure=result['supply_pressure'],
                        behavior_pressure=result['behavior_pressure'],
                        impact_days=result['impact_days']
                    )
                    session.add(impact)
                    session.commit()
                    analyze_count += 1
                    
                    if result['total_score'] != 0.0:
                        print(f"      âœ¨ {item_name}: {result['total_score']} ({result['reason']})")
                    
                    time.sleep(0.05)

            if analyze_count > 0:
                print(f"-- {analyze_count}ê°œ ì‹ ê·œ ë¶„ì„ ì™„ë£Œ")

    except Exception as e:
        print(f"ì—ëŸ¬: {e}")
    finally:
        session.close()
        print("ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ")

if __name__ == "__main__":
    # íƒ€ì„ì¡´ ì„¤ì • (ì•„ì£¼ ì˜í•˜ì…¨ìŠµë‹ˆë‹¤!)
    scheduler = BlockingScheduler(timezone='Asia/Seoul')
    
    # ìŠ¤ì¼€ì¤„ ë“±ë¡: ë§¤ì£¼ ìˆ˜ìš”ì¼ 10ì‹œ 01ë¶„
    scheduler.add_job(run_scheduler, 'cron', day_of_week='wed', hour=10, minute=1)
    
    print("â° íŒŒì´ì¬ ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • ì™„ë£Œ (ë§¤ì£¼ ìˆ˜ìš”ì¼ 10:01)")

    # ---------------------------------------------------------
    # [ì¶”ê°€] ë°°í¬ ì§í›„ ì˜ ëŒì•„ê°€ëŠ”ì§€ 'ì§€ê¸ˆ ë‹¹ì¥' í•œ ë²ˆ ì‹¤í–‰í•´ë³´ê¸°
    # ---------------------------------------------------------
    print("ğŸš€ [Self-Test] ì„œë²„ ì‹œì‘ ì§í›„ ìµœì´ˆ 1íšŒ ì‹¤í–‰ ì¤‘...")
    try:
        run_scheduler() # ì—¬ê¸°ì„œ ì—ëŸ¬ ë‚˜ë©´ ë°”ë¡œ ì•Œ ìˆ˜ ìˆìŒ!
    except Exception as e:
        print(f"âŒ ì´ˆê¸° ì‹¤í–‰ ì‹¤íŒ¨: {e}")

    # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ (Blocking)
    print("âœ… ì´ˆê¸° ì‹¤í–‰ ì™„ë£Œ. ìŠ¤ì¼€ì¤„ëŸ¬ ëŒ€ê¸° ëª¨ë“œ ì§„ì…...")
    try:
        scheduler.start()
    except (KeyboardInterrupt, SystemExit):
        pass
