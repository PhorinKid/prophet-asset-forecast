{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eb1837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a89485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (notebooks í´ë”ì˜ ìƒìœ„ í´ë”ì— ìˆëŠ” .env ë¡œë“œ)\n",
    "# ---------------------------------------------------------\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "# 2. DB ì—°ê²°\n",
    "DB_CONFIG = {\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"port\": int(os.getenv(\"DB_PORT\", 3306)),\n",
    "    \"user\": os.getenv(\"DB_USER\", \"admin\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "    \"db\": os.getenv(\"DB_NAME\", \"projectl\")\n",
    "}\n",
    "\n",
    "db_url = f\"mysql+pymysql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['db']}\"\n",
    "engine = create_engine(db_url)\n",
    "print(\"âœ… DB ì—°ê²° ì„±ê³µ!\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ (ìŠ¤í‚¤ë§ˆ ì»¬ëŸ¼ëª… ìˆ˜ì • ì™„ë£Œ)\n",
    "# ---------------------------------------------------------\n",
    "def get_item_data(item_name):\n",
    "    conn = engine.connect()\n",
    "    try:\n",
    "        # (1) ì•„ì´í…œ ID ì°¾ê¸°\n",
    "        item_sql = text(\"SELECT id FROM market_items WHERE name = :name\")\n",
    "        item_id = conn.execute(item_sql, {\"name\": item_name}).scalar()\n",
    "        \n",
    "        if not item_id:\n",
    "            print(f\"âŒ '{item_name}' ì•„ì´í…œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return None, None\n",
    "\n",
    "        print(f\"ğŸ” '{item_name}' (ID: {item_id}) ë°ì´í„° ìˆ˜ì§‘ ì¤‘...\")\n",
    "\n",
    "        # (2) ê°€ê²© ë¡œê·¸ ê°€ì ¸ì˜¤ê¸° (ì»¬ëŸ¼ëª…: current_min_price, logged_at)\n",
    "        price_sql = text(\"\"\"\n",
    "            SELECT logged_at, current_min_price\n",
    "            FROM market_price_logs\n",
    "            WHERE item_id = :item_id\n",
    "            ORDER BY logged_at ASC\n",
    "        \"\"\")\n",
    "        df_prices = pd.read_sql(price_sql, conn, params={\"item_id\": item_id})\n",
    "        \n",
    "        # (3) GPT Score ê°€ì ¸ì˜¤ê¸° (ì»¬ëŸ¼ëª…: notice_date, gpt_score)\n",
    "        notice_sql = text(\"\"\"\n",
    "            SELECT r.notice_date, i.gpt_score\n",
    "            FROM item_notice_impacts i\n",
    "            JOIN raw_notices r ON i.notice_id = r.id\n",
    "            WHERE i.item_id = :item_id\n",
    "            ORDER BY r.notice_date ASC\n",
    "        \"\"\")\n",
    "        df_notices = pd.read_sql(notice_sql, conn, params={\"item_id\": item_id})\n",
    "        \n",
    "        print(f\"   - ê°€ê²© ë¡œê·¸: {len(df_prices)}ê°œ\")\n",
    "        print(f\"   - ê´€ë ¨ ê³µì§€: {len(df_notices)}ê°œ\")\n",
    "        \n",
    "        return df_prices, df_notices\n",
    "\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# [í…ŒìŠ¤íŠ¸] ì•„ì´í…œ ì´ë¦„ ì…ë ¥\n",
    "# ---------------------------------------------------------\n",
    "TARGET_ITEM = \"ìœ ë¬¼ ì›í•œ ê°ì¸ì„œ\"  # ğŸ‘ˆ ë¶„ì„í•˜ê³  ì‹¶ì€ ì•„ì´í…œ ì´ë¦„\n",
    "df_raw, df_gpt = get_item_data(TARGET_ITEM)\n",
    "\n",
    "display(df_raw.head())\n",
    "display(df_gpt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cc3d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "# =========================================================\n",
    "# [ì—…ê·¸ë ˆì´ë“œ] í•¨ìˆ˜ 1: ì›ë³¸ ì²­ì†Œ í›„ 30ë¶„ë´‰ ë§Œë“¤ê¸°\n",
    "# =========================================================\n",
    "def preprocess_ohlc_and_fill(df_raw):\n",
    "    print(\"ğŸ§¹ [1ë‹¨ê³„] Raw ë°ì´í„° ì •ì œ ë° 30ë¶„ë´‰ ë³€í™˜...\")\n",
    "    \n",
    "    df = df_raw.copy()\n",
    "    \n",
    "    # 1. ì¸ë±ìŠ¤ ì„¤ì • (í•„ìˆ˜)\n",
    "    if 'logged_at' in df.columns:\n",
    "        df['logged_at'] = pd.to_datetime(df['logged_at'])\n",
    "        df.set_index('logged_at', inplace=True)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # ğŸš¨ [í•µì‹¬ ì¶”ê°€] ì›ë³¸(10ë¶„ ë‹¨ìœ„) ë‹¨ê³„ì—ì„œ ì´ìƒì¹˜ 1ì°¨ ì œê±°\n",
    "    # -----------------------------------------------------\n",
    "    # 10ë¶„ ë°ì´í„°ì´ë¯€ë¡œ í•˜ë£¨(24ì‹œê°„)ë¥¼ ë³´ë ¤ë©´ windowê°€ ì•½ 144ê°œ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "    # (6ê°œ/ì‹œê°„ * 24ì‹œê°„ = 144)\n",
    "    raw_window = 432\n",
    "    raw_sigma = 7 # ì›ë³¸ì€ ë³€ë™ì„±ì´ ë” í¬ë‹ˆ 2.0ë³´ë‹¤ ì‚´ì§ ì—¬ìœ  ìˆê²Œ 2.5 ì¶”ì²œ\n",
    "    \n",
    "    # ì›ë³¸ ê°€ê²© ì»¬ëŸ¼: 'current_min_price'\n",
    "    rolling_mean = df['current_min_price'].rolling(window=raw_window, center=True).mean()\n",
    "    rolling_std = df['current_min_price'].rolling(window=raw_window, center=True).std()\n",
    "    \n",
    "    upper = rolling_mean + (raw_sigma * rolling_std)\n",
    "    lower = rolling_mean - (raw_sigma * rolling_std)\n",
    "    \n",
    "    outliers = (df['current_min_price'] > upper) | (df['current_min_price'] < lower)\n",
    "    cnt = outliers.sum()\n",
    "    \n",
    "    if cnt > 0:\n",
    "        print(f\"   âœ¨ ì›ë³¸ ë°ì´í„°ì—ì„œ {cnt}ê°œì˜ ì´ìƒì¹˜ë¥¼ ë¯¸ë¦¬ ì œê±°í–ˆìŠµë‹ˆë‹¤!\")\n",
    "        df.loc[outliers, 'current_min_price'] = np.nan\n",
    "        df['current_min_price'] = df['current_min_price'].interpolate(method='linear')\n",
    "    # -----------------------------------------------------\n",
    "    \n",
    "    # 2. 30ë¶„ ë‹¨ìœ„ Resampling (ì´ì œ ê¹¨ë—í•œ ì¬ë£Œë¡œ ìš”ë¦¬í•©ë‹ˆë‹¤)\n",
    "    df_resampled = df['current_min_price'].resample('30min').agg(['first', 'max', 'min', 'last', 'mean'])\n",
    "    df_resampled.columns = ['Open', 'High', 'Low', 'Close', 'Price_Mean']\n",
    "    \n",
    "    # 3. ë¹ˆì¹¸ ì±„ìš°ê¸°\n",
    "    df_filled = df_resampled.ffill().bfill()\n",
    "    \n",
    "    print(f\"   - ì •ì œ ì™„ë£Œ: {len(df_filled)}ê°œ êµ¬ê°„ (30ë¶„ë´‰)\")\n",
    "    return df_filled\n",
    "\n",
    "# =========================================================\n",
    "# [ì¶”ê°€ë¨] í•¨ìˆ˜ 1.5: ì´ìƒì¹˜ ì œê±° (Rolling Z-Score)\n",
    "# =========================================================\n",
    "def clean_outliers_rolling(df, column='Close', window=48, sigma=3):\n",
    "    print(f\"ğŸ§¼ [1.5ë‹¨ê³„] ì´ìƒì¹˜ ì œê±° ì¤‘... (Window={window}, Sigma={sigma})\")\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # ì´ë™ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°\n",
    "    rolling_mean = df_clean[column].rolling(window=window, center=True).mean()\n",
    "    rolling_std = df_clean[column].rolling(window=window, center=True).std()\n",
    "    \n",
    "    # ì´ìƒì¹˜ íŒë³„ ê¸°ì¤€\n",
    "    upper_bound = rolling_mean + (sigma * rolling_std)\n",
    "    lower_bound = rolling_mean - (sigma * rolling_std)\n",
    "    \n",
    "    # ì´ìƒì¹˜ ì¡°ê±´ í™•ì¸ ë° ê°œìˆ˜ ì¹´ìš´íŠ¸\n",
    "    outlier_mask = (df_clean[column] > upper_bound) | (df_clean[column] < lower_bound)\n",
    "    outlier_count = outlier_mask.sum()\n",
    "    \n",
    "    if outlier_count > 0:\n",
    "        print(f\"   ğŸš¨ {outlier_count}ê°œì˜ íŠ€ëŠ” ê°€ê²© ë°œê²¬! ë¶€ë“œëŸ½ê²Œ ë³´ì •í•©ë‹ˆë‹¤.\")\n",
    "        # ì´ìƒì¹˜ë¥¼ NaNìœ¼ë¡œ ë³€ê²½ í›„ ë³´ê°„(Interpolation)\n",
    "        df_clean.loc[outlier_mask, column] = np.nan\n",
    "        df_clean[column] = df_clean[column].interpolate(method='linear')\n",
    "    else:\n",
    "        print(\"   âœ… ë°ì´í„°ê°€ ì•„ì£¼ ê¹¨ë—í•©ë‹ˆë‹¤.\")\n",
    "        \n",
    "    return df_clean\n",
    "\n",
    "# =========================================================\n",
    "# í•¨ìˆ˜ 2: GPT ìŠ¤ì½”ì–´ ë§¤í•‘ (ë‚ ì§œ ê³„ì‚° ë¡œì§)\n",
    "# =========================================================\n",
    "def apply_gpt_scores(df_price, df_gpt):\n",
    "    print(\"ğŸ¤– [2ë‹¨ê³„] GPT ê³µì§€ì‚¬í•­ ì ìˆ˜ ë§¤í•‘ ì¤‘...\")\n",
    "    \n",
    "    df = df_price.copy()\n",
    "    df['GPT_Score'] = 0.0 # ê¸°ë³¸ê°’ 0\n",
    "    \n",
    "    if df_gpt is None or df_gpt.empty:\n",
    "        print(\"   - ê³µì§€ì‚¬í•­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ì ìˆ˜ 0ìœ¼ë¡œ ì§„í–‰)\")\n",
    "        return df\n",
    "\n",
    "    count = 0\n",
    "    for idx, row in df_gpt.iterrows():\n",
    "        notice_date = pd.to_datetime(row['notice_date'])\n",
    "        score = row['gpt_score']\n",
    "        \n",
    "        # [ê·œì¹™ ì ìš©] ê³µì§€ì¼ 10:00 ~ 7ì¼ ë’¤ 06:00\n",
    "        start_time = notice_date.replace(hour=10, minute=0, second=0)\n",
    "        end_time = (notice_date + timedelta(days=7)).replace(hour=6, minute=0, second=0)\n",
    "        \n",
    "        # í•´ë‹¹ ê¸°ê°„ ë§ˆìŠ¤í‚¹\n",
    "        mask = (df.index >= start_time) & (df.index < end_time)\n",
    "        \n",
    "        if mask.any():\n",
    "            df.loc[mask, 'GPT_Score'] = score\n",
    "            count += 1\n",
    "            \n",
    "    print(f\"   - ì´ {count}ê±´ì˜ ê³µì§€ì‚¬í•­ ì ìˆ˜ ë°˜ì˜ ì™„ë£Œ\")\n",
    "    return df\n",
    "\n",
    "# =========================================================\n",
    "# [ì‹¤í–‰] íŒŒì´í”„ë¼ì¸ ì—°ê²° (ìˆœì„œ ì¤‘ìš”!)\n",
    "# =========================================================\n",
    "\n",
    "# 1. ê°€ê²© ë°ì´í„° 1ì°¨ ì •ì œ (ë¹ˆì¹¸ ì±„ìš°ê¸°)\n",
    "df_temp = preprocess_ohlc_and_fill(df_raw)\n",
    "\n",
    "# 2. [ì¶”ê°€] ì´ìƒì¹˜ ì œê±° (ì—¬ê¸°ì„œ íŠ€ëŠ” ê°’ì„ ì¡ìŠµë‹ˆë‹¤!)\n",
    "df_clean_price = clean_outliers_rolling(df_temp, column='Price_Mean', window=48, sigma=3)\n",
    "\n",
    "# 3. GPT ì ìˆ˜ ê²°í•©\n",
    "df_final = apply_gpt_scores(df_clean_price, df_gpt)\n",
    "\n",
    "# 4. ê²°ê³¼ í™•ì¸\n",
    "print(\"-\" * 30)\n",
    "print(f\"ğŸ—“ï¸ ë°ì´í„° ê¸°ê°„: {df_final.index.min()} ~ {df_final.index.max()}\")\n",
    "print(\"-\" * 30)\n",
    "display(df_final.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef3d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ì‹œê°í™” (í™•ì¸ìš©)\n",
    "# ---------------------------------------------------------\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# ê°€ê²© ê·¸ë˜í”„ (íŒŒë€ìƒ‰)\n",
    "ax1 = plt.gca()\n",
    "ax1.plot(df_final.index, df_final['Price_Mean'], color='blue', label='Avg Price')\n",
    "ax1.set_ylabel('Price (Gold)')\n",
    "\n",
    "# GPT ì ìˆ˜ ê·¸ë˜í”„ (ë¹¨ê°„ìƒ‰, yì¶• ê³µìœ )\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(df_final.index, df_final['GPT_Score'], color='red', linestyle='--', alpha=0.5, label='GPT Score')\n",
    "ax2.set_ylabel('GPT Score')\n",
    "ax2.set_ylim(-1.5, 1.5)\n",
    "\n",
    "# 2. ëˆˆê¸ˆ í˜•ì‹: 'ì›”-ì¼' í˜•íƒœë¡œ ë³´ì—¬ì¤˜ë¼ (ì˜ˆ: 01-29)\n",
    "# ì—°ë„ê¹Œì§€ ë³´ê³  ì‹¶ìœ¼ë©´ '%Y-%m-%d'ë¡œ ë°”ê¾¸ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "ax1.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.WEDNESDAY, interval=1))\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "ax1.grid(True, which='major', axis='x', linestyle='--', alpha=0.5) # ìˆ˜ìš”ì¼ë§ˆë‹¤ ì„¸ë¡œ ì ì„  ì¶”ê°€\n",
    "\n",
    "plt.title(f\"[{TARGET_ITEM}] Price Trend vs GPT Score\")\n",
    "plt.show()\n",
    "\n",
    "# ë°ì´í„° í™•ì¸\n",
    "display(df_final.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70752a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. ì›ë³¸ ë³µì‚¬\n",
    "df_ml = df_final.copy()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. ê¸°ìˆ ì  ì§€í‘œ (ì´ë™í‰ê· , ë³€ë™ì„±, RSI)\n",
    "# ---------------------------------------------------------\n",
    "# ê°€ê²©ì˜ íë¦„(Trend)ì„ ëª¨ë¸ì—ê²Œ ì•Œë ¤ì¤ë‹ˆë‹¤.\n",
    "df_ml['MA_5'] = df_ml['Close'].rolling(window=5).mean()    # 2.5ì‹œê°„ í‰ê· \n",
    "df_ml['MA_48'] = df_ml['Close'].rolling(window=48).mean()  # 24ì‹œê°„(1ì¼) í‰ê· \n",
    "df_ml['Std_20'] = df_ml['Close'].rolling(window=20).std()  # ë³€ë™ì„±\n",
    "\n",
    "# RSI (ìƒëŒ€ê°•ë„ì§€ìˆ˜)\n",
    "delta = df_ml['Close'].diff()\n",
    "gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "rs = gain / loss\n",
    "df_ml['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. [í•µì‹¬] Lag Features (ì‹œì°¨ ë°ì´í„°)\n",
    "# ---------------------------------------------------------\n",
    "# ëª¨ë¸ í•™ìŠµìš©ìœ¼ë¡œ \"ê³¼ê±°ì˜ ì •ë‹µ\"ì„ ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘ëŠ” ê²ë‹ˆë‹¤.\n",
    "# (ë‚˜ì¤‘ì— ì˜ˆì¸¡í•  ë•ŒëŠ” ì´ ì»¬ëŸ¼ì„ ìš°ë¦¬ê°€ ì§ì ‘ ì±„ì›Œë„£ìœ¼ë©° ì˜ˆì¸¡í•´ì•¼ í•©ë‹ˆë‹¤)\n",
    "df_ml['Close_Lag1'] = df_ml['Close'].shift(1)  # 30ë¶„ ì „\n",
    "df_ml['Close_Lag2'] = df_ml['Close'].shift(2)  # 1ì‹œê°„ ì „\n",
    "df_ml['GPT_Lag1'] = df_ml['GPT_Score'].shift(1) # 30ë¶„ ì „ ê³µì§€ ì ìˆ˜\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. ì‹œê°„ ì •ë³´ (Time Features)\n",
    "# ---------------------------------------------------------\n",
    "# ë¯¸ë˜ì˜ ì‹œê°„(ìš”ì¼, ì‹œê°„)ì€ ìš°ë¦¬ê°€ ë‹¬ë ¥ë§Œ ë³´ë©´ 100% ì•Œ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•„ì£¼ ì¢‹ì€ íŒíŠ¸ì…ë‹ˆë‹¤.\n",
    "df_ml['Hour'] = df_ml.index.hour\n",
    "df_ml['DayOfWeek'] = df_ml.index.dayofweek # 0:ì›” ~ 6:ì¼\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. Target (ì •ë‹µì§€: ë‹¤ìŒ 30ë¶„ ë’¤ì˜ ê°€ê²©)\n",
    "# ---------------------------------------------------------\n",
    "df_ml['Target'] = df_ml['Close'].shift(-1)\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì œê±° (ì´ë™í‰ê·  ë“±ìœ¼ë¡œ ìƒê¸´ ì•ë¶€ë¶„ ë¹ˆì¹¸ ì‚­ì œ)\n",
    "df_ml = df_ml.dropna()\n",
    "\n",
    "print(f\"ğŸ“š ë¨¸ì‹ ëŸ¬ë‹ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {df_ml.shape}\")\n",
    "display(df_ml.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed0ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import timedelta\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. í•™ìŠµ ë°ì´í„° ì¤€ë¹„ (ê·œì¹™: 2ì›” 4ì¼ 06:00 ì´ì „ë§Œ ì‚¬ìš©)\n",
    "# ---------------------------------------------------------\n",
    "# df_mlì€ ì´ë¯¸ ì •ì œ ë° í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ì´ ëë‚œ ë°ì´í„°ë¼ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
    "train_cutoff = pd.to_datetime(\"2026-02-04 06:00:00\")\n",
    "\n",
    "features = [\n",
    "    'MA_5', 'MA_48', 'Std_20', 'RSI',\n",
    "    'Close_Lag1', 'Close_Lag2', 'GPT_Lag1',\n",
    "    'Hour', 'DayOfWeek'\n",
    "]\n",
    "target = 'Target'\n",
    "\n",
    "# í•™ìŠµìš© ë°ì´í„° (Cutoff ì´ì „)\n",
    "X_train = df_ml[df_ml.index < train_cutoff][features]\n",
    "y_train = df_ml[df_ml.index < train_cutoff][target]\n",
    "\n",
    "# ê²€ì¦ìš© ë°ì´í„° (Cutoff ì´í›„ ~ í˜„ì¬) - ê³¼ì í•© ë°©ì§€ìš©\n",
    "X_valid = df_ml[df_ml.index >= train_cutoff][features]\n",
    "y_valid = df_ml[df_ml.index >= train_cutoff][target]\n",
    "\n",
    "print(f\"ğŸ“š XGB í•™ìŠµ ë°ì´í„°: {X_train.shape} ( ~ {train_cutoff})\")\n",
    "print(f\"ğŸ“ XGB ê²€ì¦ ë°ì´í„°: {X_valid.shape}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. XGBoost ëª¨ë¸ í•™ìŠµ\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\nğŸ”¥ XGBoost í•™ìŠµ ì‹œì‘...\")\n",
    "model_xgb = xgb.XGBRegressor(\n",
    "    n_estimators=2000,       # í•™ìŠµ íšŸìˆ˜ (ë„‰ë„‰í•˜ê²Œ)\n",
    "    learning_rate=0.01,      # ì²œì²œíˆ ê¼¼ê¼¼í•˜ê²Œ\n",
    "    max_depth=6,             # ë‚˜ë¬´ ê¹Šì´\n",
    "    subsample=0.8,           # ë°ì´í„° ìƒ˜í”Œë§\n",
    "    colsample_bytree=0.8,    # ì»¬ëŸ¼ ìƒ˜í”Œë§\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    early_stopping_rounds=50 # 50ë²ˆ ë™ì•ˆ ì„±ëŠ¥ í–¥ìƒ ì—†ìœ¼ë©´ ë©ˆì¶¤\n",
    ")\n",
    "\n",
    "model_xgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    verbose=False  # ë¡œê·¸ ë„ˆë¬´ ë§ì´ ëœ¨ë©´ ì§€ì €ë¶„í•´ì„œ ê»ìŠµë‹ˆë‹¤\n",
    ")\n",
    "print(\"âœ… XGBoost í•™ìŠµ ì™„ë£Œ!\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. [í•µì‹¬] ë¯¸ë˜ 3ì¼ ì¬ê·€ì  ì˜ˆì¸¡ (Recursive Forecasting)\n",
    "# ---------------------------------------------------------\n",
    "# NeuralProphetì€ ì•Œì•„ì„œ í•´ì£¼ì§€ë§Œ, XGBëŠ” ìš°ë¦¬ê°€ ì§ì ‘ Loopë¥¼ ëŒë ¤ì•¼ í•©ë‹ˆë‹¤.\n",
    "print(f\"ğŸ”® ì§€ê¸ˆ({df_ml.index[-1]})ë¶€í„° í–¥í›„ 3ì¼ê°„ ì˜ˆì¸¡ ì‹œì‘...\")\n",
    "\n",
    "future_predictions = []\n",
    "future_dates = []\n",
    "\n",
    "# ê°€ì¥ ë§ˆì§€ë§‰ ë°ì´í„°(í˜„ì¬ ì‹œì )ë¥¼ ê°€ì ¸ì™€ì„œ ì‹œì‘ì ìœ¼ë¡œ ì‚¼ìŠµë‹ˆë‹¤.\n",
    "last_row = df_ml.iloc[[-1]].copy()\n",
    "current_time = last_row.index[0]\n",
    "\n",
    "# 144ìŠ¤í…(3ì¼) ë°˜ë³µ\n",
    "for i in range(144):\n",
    "    # 1. í˜„ì¬ ìƒíƒœë¡œ ë‹¤ìŒ ìŠ¤í… ì˜ˆì¸¡\n",
    "    pred_price = model_xgb.predict(last_row[features])[0]\n",
    "    \n",
    "    # 2. ê²°ê³¼ ì €ì¥\n",
    "    next_time = current_time + timedelta(minutes=30)\n",
    "    future_predictions.append(pred_price)\n",
    "    future_dates.append(next_time)\n",
    "    \n",
    "    # 3. [ì¤‘ìš”] ë‹¤ìŒ ì˜ˆì¸¡ì„ ìœ„í•´ 'ê³¼ê±° ì •ë³´(Lags)' ì—…ë°ì´íŠ¸ (Shift)\n",
    "    # ì˜¤ëŠ˜ ì˜ˆì¸¡í•œ ê°€ê²©(pred_price)ì´ ë‚´ì¼ì˜ 'ì–´ì œ ê°€ê²©(Lag1)'ì´ ë©ë‹ˆë‹¤.\n",
    "    \n",
    "    # Lag2 <- Lag1 (ë°€ì–´ë‚´ê¸°)\n",
    "    last_row['Close_Lag2'] = last_row['Close_Lag1']\n",
    "    # Lag1 <- ë°©ê¸ˆ ì˜ˆì¸¡í•œ ê°’ (ì±„ìš°ê¸°)\n",
    "    last_row['Close_Lag1'] = pred_price\n",
    "    \n",
    "    # GPT Lag (ë¯¸ë˜ ê³µì§€ì‚¬í•­ì€ ì—†ìœ¼ë¯€ë¡œ 0ìœ¼ë¡œ ê°€ì •, ë§Œì•½ ìˆìœ¼ë©´ ì—¬ê¸°ì„œ ë„£ì–´ì¤Œ)\n",
    "    last_row['GPT_Lag1'] = 0.0\n",
    "    \n",
    "    # ì‹œê°„ ì •ë³´ ì—…ë°ì´íŠ¸\n",
    "    last_row['Hour'] = next_time.hour\n",
    "    last_row['DayOfWeek'] = next_time.dayofweek\n",
    "    \n",
    "    # (ì°¸ê³ ) MA, RSI ë“±ì€ ì¬ê·€ì ìœ¼ë¡œ ê³„ì‚°í•˜ê¸° ë³µì¡í•˜ë¯€ë¡œ \n",
    "    # ë‹¨ê¸° ì˜ˆì¸¡ì—ì„œëŠ” ì§ì „ ê°’ì„ ìœ ì§€í•˜ê±°ë‚˜, Lagê°’ë§Œìœ¼ë¡œ ì¶”ì„¸ë¥¼ ì¡ê²Œ ë‘¡ë‹ˆë‹¤.\n",
    "    \n",
    "    # í˜„ì¬ ì‹œê°„ ê°±ì‹ \n",
    "    current_time = next_time\n",
    "\n",
    "# DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "forecast_3days_xgb = pd.DataFrame({\n",
    "    'ë‚ ì§œ': future_dates,\n",
    "    'ì˜ˆì¸¡ê°€ê²©': future_predictions\n",
    "})\n",
    "\n",
    "print(\"âœ… XGB ë¯¸ë˜ ì˜ˆì¸¡ ì™„ë£Œ!\")\n",
    "display(forecast_3days_xgb.head())\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. ê²°ê³¼ ì‹œê°í™”\n",
    "# ---------------------------------------------------------\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# (1) ê³¼ê±° ë°ì´í„° (ìµœê·¼ 5ì¼ì¹˜)\n",
    "recent_view = df_ml.tail(144)\n",
    "plt.plot(recent_view.index, recent_view['Close'], label='History', color='gray', alpha=0.5)\n",
    "\n",
    "# (2) XGB ì˜ˆì¸¡ì„ \n",
    "plt.plot(forecast_3days_xgb['ë‚ ì§œ'], forecast_3days_xgb['ì˜ˆì¸¡ê°€ê²©'],\n",
    "         label='XGB Forecast (Next 3 Days)', color='green', linewidth=2)\n",
    "\n",
    "# ê¸°ì¤€ì„ \n",
    "current_now = df_ml.index[-1]\n",
    "plt.axvline(current_now, color='blue', linestyle=':', label='Now')\n",
    "\n",
    "plt.title(f\"[{TARGET_ITEM}] XGBoost Price Forecast\", fontsize=16)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# ë‚ ì§œ í¬ë§·\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.WEDNESDAY, interval=1))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "ax.grid(True, which='major', axis='x', linestyle='--', alpha=0.5) # ìˆ˜ìš”ì¼ë§ˆë‹¤ ì„¸ë¡œ ì ì„  ì¶”ê°€plt.show()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. ìš”ì•½ ë¦¬í¬íŠ¸\n",
    "# ---------------------------------------------------------\n",
    "min_xgb = forecast_3days_xgb['ì˜ˆì¸¡ê°€ê²©'].min()\n",
    "max_xgb = forecast_3days_xgb['ì˜ˆì¸¡ê°€ê²©'].max()\n",
    "last_xgb = forecast_3days_xgb['ì˜ˆì¸¡ê°€ê²©'].iloc[-1]\n",
    "\n",
    "print(f\"\\nğŸ“Š [XGBoost 3ì¼ ì˜ˆì¸¡ ë¦¬í¬íŠ¸]\")\n",
    "print(f\"   - ì˜ˆìƒ ìµœì €ê°€: {min_xgb:.0f} G\")\n",
    "print(f\"   - ì˜ˆìƒ ìµœê³ ê°€: {max_xgb:.0f} G\")\n",
    "print(f\"   - 3ì¼ ë’¤ ë§ˆê°: {last_xgb:.0f} G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5dbadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. ì ìˆ˜ ê³„ì‚° (RMSE, MAE)\n",
    "# ---------------------------------------------------------\n",
    "# 'ëª¨ì˜ê³ ì‚¬(X_valid)' ë¬¸ì œë¥¼ í’€ê²Œ ì‹œí‚µë‹ˆë‹¤.\n",
    "valid_preds = model_xgb.predict(X_valid)\n",
    "\n",
    "# ì±„ì  (ì‹¤ì œ ì •ë‹µ y_validì™€ ë¹„êµ)\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, valid_preds))\n",
    "mae = mean_absolute_error(y_valid, valid_preds)\n",
    "\n",
    "print(f\"ğŸ’¯ [ëª¨ë¸ ì„±ì í‘œ - ê²€ì¦ ë°ì´í„° ê¸°ì¤€]\")\n",
    "print(f\"   - RMSE (í‰ê·  ì˜¤ì°¨): Â±{rmse:.2f} ê³¨ë“œ\")\n",
    "print(f\"   - MAE (ì ˆëŒ€ ì˜¤ì°¨): Â±{mae:.2f} ê³¨ë“œ\")\n",
    "print(f\"   (í•´ì„: ëª¨ë¸ ì˜ˆì¸¡ì´ ì‹¤ì œ ê°€ê²©ê³¼ ì•½ {int(mae)}ê³¨ë“œ ì •ë„ ì°¨ì´ë‚©ë‹ˆë‹¤.)\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. í•™ìŠµ ê³¡ì„  (Learning Curve) - ëª¨ë¸ì´ ê³µë¶€ë¥¼ ì˜ í–ˆë‚˜?\n",
    "# ---------------------------------------------------------\n",
    "# ëª¨ë¸ì´ í•™ìŠµí•˜ë©´ì„œ ì˜¤ì°¨ê°€ ì–´ë–»ê²Œ ì¤„ì–´ë“¤ì—ˆëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "results = model_xgb.evals_result()\n",
    "epochs = len(results['validation_0']['rmse'])\n",
    "x_axis = range(0, epochs)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(x_axis, results['validation_0']['rmse'], label='Train Error (ê³µë¶€)', color='blue')\n",
    "plt.plot(x_axis, results['validation_1']['rmse'], label='Valid Error (ëª¨ì˜ê³ ì‚¬)', color='red')\n",
    "plt.title('XGBoost Learning Curve (Lower is Better)')\n",
    "plt.xlabel('Iterations (ê³µë¶€ íšŸìˆ˜)')\n",
    "plt.ylabel('RMSE (Error)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ì‹¤ì œ vs ì˜ˆì¸¡ ë¹„êµ (ìµœê·¼ 1~2ì¼)\n",
    "# ---------------------------------------------------------\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(y_valid.index, y_valid, label='Actual Price', color='black', alpha=0.5)\n",
    "plt.plot(y_valid.index, valid_preds, label='XGB Prediction', color='red', linestyle='--')\n",
    "plt.title(f\"[{TARGET_ITEM}] Recent Performance Check (Feb 4 ~ Now)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7c332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. í‰ê°€\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# [í•„ìˆ˜] í‰ê°€ í•¨ìˆ˜ ë‹¤ì‹œ ì •ì˜ (ë„êµ¬ë“¤ì´ import ëœ ìƒíƒœì—ì„œ)\n",
    "# ---------------------------------------------------------\n",
    "def get_detailed_score(y_true, y_pred):\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_pred = np.array(y_pred).flatten()\n",
    "    \n",
    "    # 1. ê¸°ë³¸ ì˜¤ì°¨\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    # 2. í¼ì„¼íŠ¸ ì˜¤ì°¨ (MAPE)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-7))) * 100\n",
    "    \n",
    "    # 3. ì„¤ëª…ë ¥ (R2)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # 4. ë°©í–¥ ì •í™•ë„\n",
    "    true_diff = np.diff(y_true)\n",
    "    pred_diff = np.diff(y_pred)\n",
    "    correct_direction = np.sum(np.sign(true_diff) == np.sign(pred_diff))\n",
    "    dir_acc = (correct_direction / len(true_diff)) * 100\n",
    "    \n",
    "    return rmse, mae, mape, r2, dir_acc\n",
    "\n",
    "pred_xgb = model_xgb.predict(X_valid)\n",
    "\n",
    "rmse, mae, mape, r2, dir_acc = get_detailed_score(y_valid, pred_xgb)\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"âš¡ [XGBoost ì„±ì í‘œ]\")\n",
    "print(f\"   - RMSE: {rmse:.2f}\")\n",
    "print(f\"   - MAE : {mae:.2f}\")\n",
    "print(f\"   - MAPE: {mape:.2f}%\")\n",
    "print(f\"   - r2: {r2:.2f}\")\n",
    "print(f\"   - Dir Acc: {dir_acc:.1f}%\")\n",
    "print(\"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
