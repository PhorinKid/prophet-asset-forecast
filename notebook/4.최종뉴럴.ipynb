{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a89485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (notebooks í´ë”ì˜ ìƒìœ„ í´ë”ì— ìˆëŠ” .env ë¡œë“œ)\n",
    "# ---------------------------------------------------------\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "# 2. DB ì—°ê²°\n",
    "DB_CONFIG = {\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"port\": int(os.getenv(\"DB_PORT\", 3306)),\n",
    "    \"user\": os.getenv(\"DB_USER\", \"admin\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "    \"db\": os.getenv(\"DB_NAME\", \"projectl\")\n",
    "}\n",
    "\n",
    "db_url = f\"mysql+pymysql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['db']}\"\n",
    "engine = create_engine(db_url)\n",
    "print(\"âœ… DB ì—°ê²° ì„±ê³µ!\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ (ìŠ¤í‚¤ë§ˆ ì»¬ëŸ¼ëª… ìˆ˜ì • ì™„ë£Œ)\n",
    "# ---------------------------------------------------------\n",
    "def get_item_data(item_name):\n",
    "    conn = engine.connect()\n",
    "    try:\n",
    "        # (1) ì•„ì´í…œ ID ì°¾ê¸°\n",
    "        item_sql = text(\"SELECT id FROM market_items WHERE name = :name\")\n",
    "        item_id = conn.execute(item_sql, {\"name\": item_name}).scalar()\n",
    "        \n",
    "        if not item_id:\n",
    "            print(f\"âŒ '{item_name}' ì•„ì´í…œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return None, None\n",
    "\n",
    "        print(f\"ğŸ” '{item_name}' (ID: {item_id}) ë°ì´í„° ìˆ˜ì§‘ ì¤‘...\")\n",
    "\n",
    "        # (2) ê°€ê²© ë¡œê·¸ ê°€ì ¸ì˜¤ê¸° (ì»¬ëŸ¼ëª…: current_min_price, logged_at)\n",
    "        price_sql = text(\"\"\"\n",
    "            SELECT logged_at, current_min_price\n",
    "            FROM market_price_logs\n",
    "            WHERE item_id = :item_id\n",
    "            ORDER BY logged_at ASC\n",
    "        \"\"\")\n",
    "        df_prices = pd.read_sql(price_sql, conn, params={\"item_id\": item_id})\n",
    "        \n",
    "        # (3) GPT Score ê°€ì ¸ì˜¤ê¸° (ì»¬ëŸ¼ëª…: notice_date, gpt_score)\n",
    "        notice_sql = text(\"\"\"\n",
    "            SELECT r.notice_date, i.gpt_score\n",
    "            FROM item_notice_impacts i\n",
    "            JOIN raw_notices r ON i.notice_id = r.id\n",
    "            WHERE i.item_id = :item_id\n",
    "            ORDER BY r.notice_date ASC\n",
    "        \"\"\")\n",
    "        df_notices = pd.read_sql(notice_sql, conn, params={\"item_id\": item_id})\n",
    "        \n",
    "        print(f\"   - ê°€ê²© ë¡œê·¸: {len(df_prices)}ê°œ\")\n",
    "        print(f\"   - ê´€ë ¨ ê³µì§€: {len(df_notices)}ê°œ\")\n",
    "        \n",
    "        return df_prices, df_notices\n",
    "\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# [í…ŒìŠ¤íŠ¸] ì•„ì´í…œ ì´ë¦„ ì…ë ¥\n",
    "# ---------------------------------------------------------\n",
    "TARGET_ITEM = \"ìœ ë¬¼ ì›í•œ ê°ì¸ì„œ\"  # ğŸ‘ˆ ë¶„ì„í•˜ê³  ì‹¶ì€ ì•„ì´í…œ ì´ë¦„\n",
    "df_raw, df_gpt = get_item_data(TARGET_ITEM)\n",
    "\n",
    "display(df_raw.head())\n",
    "display(df_gpt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cc3d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "# =========================================================\n",
    "# [ì—…ê·¸ë ˆì´ë“œ] í•¨ìˆ˜ 1: ì›ë³¸ ì²­ì†Œ í›„ 30ë¶„ë´‰ ë§Œë“¤ê¸°\n",
    "# =========================================================\n",
    "def preprocess_ohlc_and_fill(df_raw):\n",
    "    print(\"ğŸ§¹ [1ë‹¨ê³„] Raw ë°ì´í„° ì •ì œ ë° 30ë¶„ë´‰ ë³€í™˜...\")\n",
    "    \n",
    "    df = df_raw.copy()\n",
    "    \n",
    "    # 1. ì¸ë±ìŠ¤ ì„¤ì • (í•„ìˆ˜)\n",
    "    if 'logged_at' in df.columns:\n",
    "        df['logged_at'] = pd.to_datetime(df['logged_at'])\n",
    "        df.set_index('logged_at', inplace=True)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # ğŸš¨ [í•µì‹¬ ì¶”ê°€] ì›ë³¸(10ë¶„ ë‹¨ìœ„) ë‹¨ê³„ì—ì„œ ì´ìƒì¹˜ 1ì°¨ ì œê±°\n",
    "    # -----------------------------------------------------\n",
    "    # 10ë¶„ ë°ì´í„°ì´ë¯€ë¡œ í•˜ë£¨(24ì‹œê°„)ë¥¼ ë³´ë ¤ë©´ windowê°€ ì•½ 144ê°œ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "    # (6ê°œ/ì‹œê°„ * 24ì‹œê°„ = 144)\n",
    "    raw_window = 432\n",
    "    raw_sigma = 7 # ì›ë³¸ì€ ë³€ë™ì„±ì´ ë” í¬ë‹ˆ 2.0ë³´ë‹¤ ì‚´ì§ ì—¬ìœ  ìˆê²Œ 2.5 ì¶”ì²œ\n",
    "    \n",
    "    # ì›ë³¸ ê°€ê²© ì»¬ëŸ¼: 'current_min_price'\n",
    "    rolling_mean = df['current_min_price'].rolling(window=raw_window, center=True).mean()\n",
    "    rolling_std = df['current_min_price'].rolling(window=raw_window, center=True).std()\n",
    "    \n",
    "    upper = rolling_mean + (raw_sigma * rolling_std)\n",
    "    lower = rolling_mean - (raw_sigma * rolling_std)\n",
    "    \n",
    "    outliers = (df['current_min_price'] > upper) | (df['current_min_price'] < lower)\n",
    "    cnt = outliers.sum()\n",
    "    \n",
    "    if cnt > 0:\n",
    "        print(f\"   âœ¨ ì›ë³¸ ë°ì´í„°ì—ì„œ {cnt}ê°œì˜ ì´ìƒì¹˜ë¥¼ ë¯¸ë¦¬ ì œê±°í–ˆìŠµë‹ˆë‹¤!\")\n",
    "        df.loc[outliers, 'current_min_price'] = np.nan\n",
    "        df['current_min_price'] = df['current_min_price'].interpolate(method='linear')\n",
    "    # -----------------------------------------------------\n",
    "    \n",
    "    # 2. 30ë¶„ ë‹¨ìœ„ Resampling (ì´ì œ ê¹¨ë—í•œ ì¬ë£Œë¡œ ìš”ë¦¬í•©ë‹ˆë‹¤)\n",
    "    df_resampled = df['current_min_price'].resample('30min').agg(['first', 'max', 'min', 'last', 'mean'])\n",
    "    df_resampled.columns = ['Open', 'High', 'Low', 'Close', 'Price_Mean']\n",
    "    \n",
    "    # 3. ë¹ˆì¹¸ ì±„ìš°ê¸°\n",
    "    df_filled = df_resampled.ffill().bfill()\n",
    "    \n",
    "    print(f\"   - ì •ì œ ì™„ë£Œ: {len(df_filled)}ê°œ êµ¬ê°„ (30ë¶„ë´‰)\")\n",
    "    return df_filled\n",
    "\n",
    "# =========================================================\n",
    "# [ì¶”ê°€ë¨] í•¨ìˆ˜ 1.5: ì´ìƒì¹˜ ì œê±° (Rolling Z-Score)\n",
    "# =========================================================\n",
    "def clean_outliers_rolling(df, column='Close', window=48, sigma=3):\n",
    "    print(f\"ğŸ§¼ [1.5ë‹¨ê³„] ì´ìƒì¹˜ ì œê±° ì¤‘... (Window={window}, Sigma={sigma})\")\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # ì´ë™ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°\n",
    "    rolling_mean = df_clean[column].rolling(window=window, center=True).mean()\n",
    "    rolling_std = df_clean[column].rolling(window=window, center=True).std()\n",
    "    \n",
    "    # ì´ìƒì¹˜ íŒë³„ ê¸°ì¤€\n",
    "    upper_bound = rolling_mean + (sigma * rolling_std)\n",
    "    lower_bound = rolling_mean - (sigma * rolling_std)\n",
    "    \n",
    "    # ì´ìƒì¹˜ ì¡°ê±´ í™•ì¸ ë° ê°œìˆ˜ ì¹´ìš´íŠ¸\n",
    "    outlier_mask = (df_clean[column] > upper_bound) | (df_clean[column] < lower_bound)\n",
    "    outlier_count = outlier_mask.sum()\n",
    "    \n",
    "    if outlier_count > 0:\n",
    "        print(f\"   ğŸš¨ {outlier_count}ê°œì˜ íŠ€ëŠ” ê°€ê²© ë°œê²¬! ë¶€ë“œëŸ½ê²Œ ë³´ì •í•©ë‹ˆë‹¤.\")\n",
    "        # ì´ìƒì¹˜ë¥¼ NaNìœ¼ë¡œ ë³€ê²½ í›„ ë³´ê°„(Interpolation)\n",
    "        df_clean.loc[outlier_mask, column] = np.nan\n",
    "        df_clean[column] = df_clean[column].interpolate(method='linear')\n",
    "    else:\n",
    "        print(\"   âœ… ë°ì´í„°ê°€ ì•„ì£¼ ê¹¨ë—í•©ë‹ˆë‹¤.\")\n",
    "        \n",
    "    return df_clean\n",
    "\n",
    "# =========================================================\n",
    "# í•¨ìˆ˜ 2: GPT ìŠ¤ì½”ì–´ ë§¤í•‘ (ë‚ ì§œ ê³„ì‚° ë¡œì§)\n",
    "# =========================================================\n",
    "def apply_gpt_scores(df_price, df_gpt):\n",
    "    print(\"ğŸ¤– [2ë‹¨ê³„] GPT ê³µì§€ì‚¬í•­ ì ìˆ˜ ë§¤í•‘ ì¤‘...\")\n",
    "    \n",
    "    df = df_price.copy()\n",
    "    df['GPT_Score'] = 0.0 # ê¸°ë³¸ê°’ 0\n",
    "    \n",
    "    if df_gpt is None or df_gpt.empty:\n",
    "        print(\"   - ê³µì§€ì‚¬í•­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ì ìˆ˜ 0ìœ¼ë¡œ ì§„í–‰)\")\n",
    "        return df\n",
    "\n",
    "    count = 0\n",
    "    for idx, row in df_gpt.iterrows():\n",
    "        notice_date = pd.to_datetime(row['notice_date'])\n",
    "        score = row['gpt_score']\n",
    "        \n",
    "        # [ê·œì¹™ ì ìš©] ê³µì§€ì¼ 10:00 ~ 7ì¼ ë’¤ 06:00\n",
    "        start_time = notice_date.replace(hour=10, minute=0, second=0)\n",
    "        end_time = (notice_date + timedelta(days=7)).replace(hour=6, minute=0, second=0)\n",
    "        \n",
    "        # í•´ë‹¹ ê¸°ê°„ ë§ˆìŠ¤í‚¹\n",
    "        mask = (df.index >= start_time) & (df.index < end_time)\n",
    "        \n",
    "        if mask.any():\n",
    "            df.loc[mask, 'GPT_Score'] = score\n",
    "            count += 1\n",
    "            \n",
    "    print(f\"   - ì´ {count}ê±´ì˜ ê³µì§€ì‚¬í•­ ì ìˆ˜ ë°˜ì˜ ì™„ë£Œ\")\n",
    "    return df\n",
    "\n",
    "# =========================================================\n",
    "# [ì‹¤í–‰] íŒŒì´í”„ë¼ì¸ ì—°ê²° (ìˆœì„œ ì¤‘ìš”!)\n",
    "# =========================================================\n",
    "\n",
    "# 1. ê°€ê²© ë°ì´í„° 1ì°¨ ì •ì œ (ë¹ˆì¹¸ ì±„ìš°ê¸°)\n",
    "df_temp = preprocess_ohlc_and_fill(df_raw)\n",
    "\n",
    "# 2. [ì¶”ê°€] ì´ìƒì¹˜ ì œê±° (ì—¬ê¸°ì„œ íŠ€ëŠ” ê°’ì„ ì¡ìŠµë‹ˆë‹¤!)\n",
    "df_clean_price = clean_outliers_rolling(df_temp, column='Price_Mean', window=48, sigma=3)\n",
    "\n",
    "# 3. GPT ì ìˆ˜ ê²°í•©\n",
    "df_final = apply_gpt_scores(df_clean_price, df_gpt)\n",
    "\n",
    "# 4. ê²°ê³¼ í™•ì¸\n",
    "print(\"-\" * 30)\n",
    "print(f\"ğŸ—“ï¸ ë°ì´í„° ê¸°ê°„: {df_final.index.min()} ~ {df_final.index.max()}\")\n",
    "print(\"-\" * 30)\n",
    "display(df_final.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef3d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ì‹œê°í™” (í™•ì¸ìš©)\n",
    "# ---------------------------------------------------------\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# ê°€ê²© ê·¸ë˜í”„ (íŒŒë€ìƒ‰)\n",
    "ax1 = plt.gca()\n",
    "ax1.plot(df_final.index, df_final['Price_Mean'], color='blue', label='Avg Price')\n",
    "ax1.set_ylabel('Price (Gold)')\n",
    "\n",
    "# GPT ì ìˆ˜ ê·¸ë˜í”„ (ë¹¨ê°„ìƒ‰, yì¶• ê³µìœ )\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(df_final.index, df_final['GPT_Score'], color='red', linestyle='--', alpha=0.5, label='GPT Score')\n",
    "ax2.set_ylabel('GPT Score')\n",
    "ax2.set_ylim(-1.5, 1.5)\n",
    "\n",
    "# 2. ëˆˆê¸ˆ í˜•ì‹: 'ì›”-ì¼' í˜•íƒœë¡œ ë³´ì—¬ì¤˜ë¼ (ì˜ˆ: 01-29)\n",
    "# ì—°ë„ê¹Œì§€ ë³´ê³  ì‹¶ìœ¼ë©´ '%Y-%m-%d'ë¡œ ë°”ê¾¸ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "ax1.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.WEDNESDAY, interval=1))\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "ax1.grid(True, which='major', axis='x', linestyle='--', alpha=0.5) # ìˆ˜ìš”ì¼ë§ˆë‹¤ ì„¸ë¡œ ì ì„  ì¶”ê°€\n",
    "\n",
    "plt.title(f\"[{TARGET_ITEM}] Price Trend vs GPT Score\")\n",
    "plt.show()\n",
    "\n",
    "# ë°ì´í„° í™•ì¸\n",
    "display(df_final.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fbd94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet, save, set_random_seed\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„\n",
    "# ---------------------------------------------------------\n",
    "set_random_seed(42)\n",
    "\n",
    "# PyTorch ë³´ì•ˆ í•´ì œ (í•™ìŠµ ì‹œì—” í•„ìš” ì—†ì§€ë§Œ ìŠµê´€ì ìœ¼ë¡œ ë„£ì–´ë‘ë©´ ì•ˆì „)\n",
    "_original_torch_load = torch.load\n",
    "def patched_torch_load(*args, **kwargs):\n",
    "    if 'weights_only' not in kwargs:\n",
    "        kwargs['weights_only'] = False\n",
    "    return _original_torch_load(*args, **kwargs)\n",
    "torch.load = patched_torch_load\n",
    "\n",
    "# ë°ì´í„° ì¤€ë¹„ (ì˜¤ì „ 6ì‹œ ì´ì „)\n",
    "train_cutoff = pd.to_datetime(\"2026-02-04 06:00:00\")\n",
    "df_np = df_final.reset_index()[['logged_at', 'Close', 'GPT_Score']].copy()\n",
    "df_np.columns = ['ds', 'y', 'GPT_Score']\n",
    "df_train = df_np[df_np['ds'] < train_cutoff]\n",
    "\n",
    "print(\"âœ… NeuralProphetìš© ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\")\n",
    "display(df_np.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1e2f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 2. ëª¨ë¸ ì •ì˜\n",
    "# ---------------------------------------------------------\n",
    "def NeuralProphet_fit(FORECAST_HORIZON):\n",
    "    m = NeuralProphet(\n",
    "        n_forecasts=FORECAST_HORIZON,\n",
    "        n_lags=240,\n",
    "        \n",
    "        n_changepoints=10,\n",
    "        trend_reg=1.0,\n",
    "        weekly_seasonality=True, # ìˆ˜ìš”ì¼ ì ê²€ ë“±ì˜ ì£¼ê°„ íŒ¨í„´ í•™ìŠµ\n",
    "        daily_seasonality=True,  # ìƒˆë²½/ì €ë… íŒ¨í„´ í•™ìŠµ\n",
    "        yearly_seasonality=False,# 1ë…„ì¹˜ ë°ì´í„°ëŠ” ì•„ë‹ˆë¯€ë¡œ ë”\n",
    "        learning_rate=0.01,\n",
    "        growth='off'\n",
    "    )\n",
    "\n",
    "    # 3. GPT ì ìˆ˜(ê³µì§€ì‚¬í•­)ë¥¼ 'ë¯¸ë˜ë¥¼ ì•„ëŠ” ë³€ìˆ˜'ë¡œ ì¶”ê°€\n",
    "    # (ìš°ë¦¬ê°€ ë¯¸ë˜ ê³µì§€ì‚¬í•­ì€ ì—†ë‹¤ê³ (0) ê°€ì •í•˜ê³  ì…ë ¥í•  ê²ƒì´ê¸° ë•Œë¬¸)\n",
    "    m.add_future_regressor(\"GPT_Score\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3. ì¬í•™ìŠµ ë° ì €ì¥\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"ğŸ§  [3ì¼ ë‹¨ê¸° ì†ì„±ë°˜] ëª¨ë¸ í•™ìŠµ ì‹œì‘... (ëª©í‘œ: {FORECAST_HORIZON}ìŠ¤í…)\")\n",
    "\n",
    "    # í•™ìŠµ (ë³´ì•ˆ ì˜µì…˜ ì ìš©)\n",
    "    m.fit(df_train, freq=\"30min\", num_workers=0, checkpointing=False)\n",
    "\n",
    "    # ëª¨ë¸ ë®ì–´ì“°ê¸°\n",
    "    model_filename = \"lostark_price_model.np\"\n",
    "    save(m, model_filename)\n",
    "\n",
    "    print(f\"âœ… ìµœì í™”ëœ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_filename}\")\n",
    "    print(\"   ì´ì œ ì´ ëª¨ë¸ì€ '3ì¼ ë’¤'ê¹Œì§€ë§Œ ì˜ˆì¸¡í•˜ì§€ë§Œ, ê·¸ë§Œí¼ ë” ì •êµí•  ê²ë‹ˆë‹¤!\")\n",
    "\n",
    "FORECAST_HORIZON = 144\n",
    "# NeuralProphet_fit(FORECAST_HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf4bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from neuralprophet import load\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# [í•„ìˆ˜] 1. PyTorch 2.6 ë³´ì•ˆ ì ê¸ˆ í•´ì œ (ë§ˆìŠ¤í„°í‚¤)\n",
    "# ---------------------------------------------------------\n",
    "# ì €ì¥ëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ë•Œ ì—ëŸ¬ê°€ ë‚˜ì§€ ì•Šë„ë¡ í•˜ëŠ” ì•ˆì „ì¥ì¹˜ì…ë‹ˆë‹¤.\n",
    "# _original_torch_load = torch.load\n",
    "# def patched_torch_load(*args, **kwargs):\n",
    "#     if 'weights_only' not in kwargs:\n",
    "#         kwargs['weights_only'] = False\n",
    "#     return _original_torch_load(*args, **kwargs)\n",
    "# torch.load = patched_torch_load\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (Load)\n",
    "# ---------------------------------------------------------\n",
    "print(\"ğŸ“‚ [3ì¼ ì˜ˆì¸¡ ì „ìš©] ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...\")\n",
    "# ì•„ê¹Œ ì €ì¥í•œ íŒŒì¼ëª… (lostark_price_model.np)\n",
    "loaded_model = load(\"lostark_price_model.np\")\n",
    "print(\"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ! (í•™ìŠµ ê³¼ì • ì—†ì´ ë°”ë¡œ ì˜ˆì¸¡ ê°€ëŠ¥)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1227ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 3. 'í˜„ì¬(Now)' ì„¤ì • ë° ìµœì‹  ë°ì´í„° ì¤€ë¹„\n",
    "# ---------------------------------------------------------\n",
    "# [ì‹¤ì „ìš©] ì„œë²„ì—ì„œëŠ” ì•„ë˜ ì½”ë“œë¥¼ ì£¼ì„ í•´ì œí•´ì„œ ì“°ì„¸ìš”!\n",
    "current_now = pd.Timestamp.now()\n",
    "\n",
    "# ì „ì²´ ë°ì´í„° ì¤‘ 'í˜„ì¬ ì‹œê°„(Now) ì´ì „'ì˜ ë°ì´í„°ë§Œ ì˜ë¼ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "df_recent = df_np[df_np['ds'] <= current_now].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c780dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 4. ë¯¸ë˜ 3ì¼ ì˜ˆì¸¡ ì¤€ë¹„\n",
    "# ---------------------------------------------------------\n",
    "# ì˜ˆì¸¡ ê¸°ê°„: 3ì¼ * 24ì‹œê°„ * 2 (30ë¶„ ë‹¨ìœ„) = 144ê°œ\n",
    "forecast_steps = 144\n",
    "\n",
    "# ë¯¸ë˜ GPT ì ìˆ˜(ê³µì§€ì‚¬í•­) ì¤€ë¹„ (3ì¼ì¹˜ = 144ê°œ)\n",
    "# (ë§Œì•½ ë‚´ì¼ ì ê²€ ê³µì§€ê°€ ìˆë‹¤ë©´ ì—¬ê¸°ì— ì ìˆ˜ë¥¼ ë„£ì–´ì£¼ë©´ ë©ë‹ˆë‹¤)\n",
    "future_regressors = pd.DataFrame(data={'GPT_Score': [0.0] * forecast_steps})\n",
    "\n",
    "# [í•µì‹¬] df_recent(ê³¼ê±°~í˜„ì¬)ë¥¼ ë„£ì–´ì£¼ë©´, ìë™ìœ¼ë¡œ 'í˜„ì¬' ì´í›„ì˜ ë‚ ì§œë¥¼ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.\n",
    "future = loaded_model.make_future_dataframe(\n",
    "    df_recent,\n",
    "    periods=forecast_steps,\n",
    "    n_historic_predictions=False,\n",
    "    regressors_df=future_regressors\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. [ì§„ì§œ ìµœì¢…] ëŒ€ê°ì„  ì¶”ì¶œë²•ìœ¼ë¡œ NaN ì™„ë²½ í•´ê²°\n",
    "# ---------------------------------------------------------\n",
    "print(f\"ğŸ”® ì§€ê¸ˆ({current_now})ë¶€í„° í–¥í›„ 3ì¼ê°„ ì˜ˆì¸¡ ë°ì´í„° ì¶”ì¶œ ì¤‘...\")\n",
    "\n",
    "# 1. ì˜ˆì¸¡ ì‹¤í–‰\n",
    "forecast = loaded_model.predict(future)\n",
    "\n",
    "# 2. ë¯¸ë˜ ë‚ ì§œ í–‰ë“¤ë§Œ ë”°ë¡œ ëª¨ìë‹ˆë‹¤. (yê°€ NaNì¸ êµ¬ê°„)\n",
    "future_rows = forecast[forecast['y'].isnull()].copy()\n",
    "\n",
    "# 3. ê° í–‰ì—ì„œ ìì‹ ì˜ ìœ„ì¹˜(ië²ˆì§¸ ë¯¸ë˜)ì— ë§ëŠ” yhat{i} ê°’ì„ ë½‘ìŠµë‹ˆë‹¤.\n",
    "# ì˜ˆ: 1ë²ˆì§¸ ë¯¸ë˜ í–‰ì—ì„  yhat1, 144ë²ˆì§¸ ë¯¸ë˜ í–‰ì—ì„  yhat144ë¥¼ ê°€ì ¸ì˜´\n",
    "valid_preds = []\n",
    "for i in range(1, len(future_rows) + 1):\n",
    "    row_idx = future_rows.index[i-1]\n",
    "    col_name = f'yhat{i}'\n",
    "    valid_preds.append(future_rows.loc[row_idx, col_name])\n",
    "\n",
    "# 4. ì´ì œ NaN ì—†ëŠ” ê¹¨ë—í•œ ë°ì´í„°í”„ë ˆì„ ìƒì„±!\n",
    "forecast_3days = pd.DataFrame({\n",
    "    'ë‚ ì§œ': future_rows['ds'].values,\n",
    "    'ì˜ˆì¸¡ê°€ê²©': valid_preds\n",
    "})\n",
    "\n",
    "print(\"âœ… NaN í•´ê²° ì™„ë£Œ! ì´ì œ ìˆ«ìê°€ ê½‰ ì°¨ ìˆìŠµë‹ˆë‹¤.\")\n",
    "display(forecast_3days.head(10))\n",
    "display(forecast_3days.tail(5)) # í¬ë¦°ë‹˜ì´ ë§ì”€í•˜ì‹  ê·¸ ë§ˆì§€ë§‰ í–‰ì˜ ê°’ í™•ì¸!\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 6. ê²°ê³¼ ì‹œê°í™”\n",
    "# ---------------------------------------------------------\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# (1) ìµœì‹  íë¦„ (Now ê¸°ì¤€ ê³¼ê±° 2ì¼ì¹˜ë§Œ ë³´ì—¬ì£¼ê¸°)\n",
    "recent_view = df_recent.tail(144)\n",
    "plt.plot(recent_view['ds'], recent_view['y'], label='Recent History (Past 2 Days)', color='gray', alpha=0.5)\n",
    "\n",
    "# (2) 3ì¼ ë’¤ ì˜ˆì¸¡ì„  (Now ~ Future)\n",
    "plt.plot(forecast_3days['ë‚ ì§œ'], forecast_3days['ì˜ˆì¸¡ê°€ê²©'], label='Future Forecast (Next 3 Days)', color='red', linewidth=1.2)\n",
    "\n",
    "# ê¸°ì¤€ì„  (Now)\n",
    "plt.axvline(current_now, color='blue', linestyle=':', label='Current Time (Now)')\n",
    "\n",
    "# ìŠ¤íƒ€ì¼ ì„¤ì •\n",
    "plt.title(f\"[{TARGET_ITEM}] Price Forecast (Next 3 Days)\", fontsize=16)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Xì¶• ë‚ ì§œ í¬ë§·\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.WEDNESDAY, interval=1))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "ax.grid(True, which='major', axis='x', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 7. ìš”ì•½ ë¦¬í¬íŠ¸\n",
    "# ---------------------------------------------------------\n",
    "min_p = forecast_3days['ì˜ˆì¸¡ê°€ê²©'].min()\n",
    "max_p = forecast_3days['ì˜ˆì¸¡ê°€ê²©'].max()\n",
    "last_p = forecast_3days['ì˜ˆì¸¡ê°€ê²©'].iloc[-1]\n",
    "\n",
    "print(f\"\\nğŸ“Š [3ì¼ ë‹¨ê¸° ì˜ˆì¸¡ ë¦¬í¬íŠ¸]\")\n",
    "print(f\"   - ì˜ˆì¸¡ êµ¬ê°„: {forecast_3days['ë‚ ì§œ'].iloc[0]} ~ {forecast_3days['ë‚ ì§œ'].iloc[-1]}\")\n",
    "print(f\"   - ì˜ˆìƒ ìµœì €ê°€: {min_p:.0f} G\")\n",
    "print(f\"   - ì˜ˆìƒ ìµœê³ ê°€: {max_p:.0f} G\")\n",
    "print(f\"   - 3ì¼ ë’¤ ë§ˆê°: {last_p:.0f} G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e37496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralprophet import load\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# =========================================================\n",
    "# 1. í‰ê°€ í•¨ìˆ˜ (LightGBMê³¼ ë™ì¼)\n",
    "# =========================================================\n",
    "def get_detailed_score(y_true, y_pred):\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_pred = np.array(y_pred).flatten()\n",
    "    min_len = min(len(y_true), len(y_pred))\n",
    "    y_true = y_true[:min_len]\n",
    "    y_pred = y_pred[:min_len]\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-7))) * 100\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    true_diff = np.diff(y_true)\n",
    "    pred_diff = np.diff(y_pred)\n",
    "    dir_acc = (np.sum(np.sign(true_diff) == np.sign(pred_diff)) / len(true_diff)) * 100\n",
    "    return rmse, mae, mape, r2, dir_acc\n",
    "\n",
    "# =========================================================\n",
    "# 2. ëª¨ë¸ ë¡œë“œ ë° ë°ì´í„° ì¤€ë¹„\n",
    "# =========================================================\n",
    "print(\"ğŸ“‚ ëª¨ë¸ ë¡œë”© ë° ë¯¸ë¼(Dummy) ë°ì´í„° ì¤€ë¹„ ì¤‘...\")\n",
    "try:\n",
    "    m = load(\"lostark_price_model.np\")\n",
    "except:\n",
    "    m = None\n",
    "\n",
    "if m:\n",
    "    # (1) ì›ë³¸ ë°ì´í„° ì¤€ë¹„\n",
    "    df_np = df_final.reset_index().rename(columns={'logged_at': 'ds', 'Close': 'y'})\n",
    "    df_np = df_np[['ds', 'y', 'GPT_Score']]\n",
    "    df_np['ds'] = pd.to_datetime(df_np['ds'])\n",
    "    df_np['GPT_Score'] = df_np['GPT_Score'].fillna(0.0)\n",
    "\n",
    "    # (2) â˜… [í•µì‹¬ ì „ëµ] ë¯¸ë¼ ë°ì´í„°(Dummy) 144ê°œ ìƒì„±\n",
    "    last_date = df_np['ds'].max()\n",
    "    print(f\"   - ì›ë³¸ ë°ì´í„° ë: {last_date}\")\n",
    "    \n",
    "    # 30ë¶„ ê°„ê²©ìœ¼ë¡œ ë¯¸ë˜ 144ê°œ(3ì¼ì¹˜) ë‚ ì§œ ìƒì„±\n",
    "    future_dates = pd.date_range(start=last_date + pd.Timedelta(minutes=30), periods=144, freq='30min')\n",
    "    \n",
    "    # ë¯¸ë¼ ë°ì´í„°í”„ë ˆì„\n",
    "    df_dummy = pd.DataFrame({\n",
    "        'ds': future_dates,\n",
    "        'y': np.nan,         # ê°€ê²©ì€ ëª¨ë¦„ (ìƒê´€ì—†ìŒ)\n",
    "        'GPT_Score': 0.0     # ë¯¸ë˜ ê³µì§€ ì—†ìŒìœ¼ë¡œ ê°€ì •\n",
    "    })\n",
    "    \n",
    "    # (3) ì›ë³¸ + ë¯¸ë¼ í•©ì¹˜ê¸°\n",
    "    df_extended = pd.concat([df_np, df_dummy], ignore_index=True)\n",
    "    print(f\"   - ë¯¸ë¼ íˆ¬ì²™ ì™„ë£Œ! (ì´ ë°ì´í„° ê¸¸ì´: {len(df_np)} -> {len(df_extended)})\")\n",
    "\n",
    "    # =========================================================\n",
    "    # 3. ì˜ˆì¸¡ ìˆ˜í–‰ (Extended ë°ì´í„°ë¡œ)\n",
    "    # =========================================================\n",
    "    print(\"ğŸ”® ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘... (ì´ì œ ì˜ë¼ë¨¹í˜€ë„ ì•ˆì „í•¨)\")\n",
    "    \n",
    "    # ì—¬ê¸°ì„œ ëª¨ë¸ì´ ë’¤ìª½ 144ê°œë¥¼ ì˜ë¼ë¨¹ì§€ë§Œ, ê·¸ê±´ ìš°ë¦¬ê°€ ë§Œë“  'ë¯¸ë¼'ì…ë‹ˆë‹¤.\n",
    "    forecast = m.predict(df_extended)\n",
    "    \n",
    "    # =========================================================\n",
    "    # 4. ê²€ì¦ ë°ì´í„° ì¶”ì¶œ (2ì›” 4ì¼ ~ ì›ë³¸ ë)\n",
    "    # =========================================================\n",
    "    cutoff = pd.to_datetime(\"2026-02-04 06:00:00\")\n",
    "    real_end = pd.to_datetime(pd.Timestamp.now())\n",
    "    \n",
    "    # ë¯¸ë¼ ë¶€ë¶„ì€ ì œì™¸í•˜ê³ , ì§„ì§œ ë°ì´í„° êµ¬ê°„ë§Œ í•„í„°ë§\n",
    "    mask = (forecast['ds'] >= cutoff) & (forecast['ds'] <= real_end)\n",
    "    df_valid = forecast[mask].copy()\n",
    "    \n",
    "    # NaN ì œê±°\n",
    "    df_valid = df_valid.dropna(subset=['y', 'yhat1'])\n",
    "    \n",
    "    print(f\"âœ… ê²€ì¦ ë°ì´í„° í™•ë³´: {len(df_valid)}ê°œ (ì„±ê³µ!)\")\n",
    "\n",
    "    # =========================================================\n",
    "    # 5. ì„±ì í‘œ ì¶œë ¥\n",
    "    # =========================================================\n",
    "    if len(df_valid) > 0:\n",
    "        y_true = df_valid['y'].values\n",
    "        y_pred = df_valid['yhat1'].values\n",
    "        \n",
    "        rmse, mae, mape, r2, dir_acc = get_detailed_score(y_true, y_pred)\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"ğŸ§  [NeuralProphet ì„±ì í‘œ (2/4 ~ í˜„ì¬)]\")\n",
    "        print(f\"   - RMSE: {rmse:.2f}\")\n",
    "        print(f\"   - MAE : {mae:.2f}\")\n",
    "        print(f\"   - MAPE: {mape:.2f}%\")\n",
    "        print(f\"   - r2  : {r2:.2f}\")\n",
    "        print(f\"   - Dir Acc: {dir_acc:.1f}%\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # ê·¸ë˜í”„\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.plot(df_valid['ds'], y_true, label='Actual Price', color='black', alpha=0.6, linewidth=2)\n",
    "        plt.plot(df_valid['ds'], y_pred, label='NeuralProphet Prediction', color='green', linestyle='--', linewidth=2)\n",
    "        plt.title(f\"[{TARGET_ITEM}] NeuralProphet Final Result\", fontsize=16)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"âš ï¸ ë­”ê°€ ì´ìƒí•©ë‹ˆë‹¤. df_final ë°ì´í„° ê¸°ê°„ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
