{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eb1837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a89485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (notebooks í´ë”ì˜ ìƒìœ„ í´ë”ì— ìˆëŠ” .env ë¡œë“œ)\n",
    "# ---------------------------------------------------------\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "# 2. DB ì—°ê²°\n",
    "DB_CONFIG = {\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"port\": int(os.getenv(\"DB_PORT\", 3306)),\n",
    "    \"user\": os.getenv(\"DB_USER\", \"admin\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "    \"db\": os.getenv(\"DB_NAME\", \"projectl\")\n",
    "}\n",
    "\n",
    "db_url = f\"mysql+pymysql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['db']}\"\n",
    "engine = create_engine(db_url)\n",
    "print(\"âœ… DB ì—°ê²° ì„±ê³µ!\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ (ìŠ¤í‚¤ë§ˆ ì»¬ëŸ¼ëª… ìˆ˜ì • ì™„ë£Œ)\n",
    "# ---------------------------------------------------------\n",
    "def get_item_data(item_name):\n",
    "    conn = engine.connect()\n",
    "    try:\n",
    "        # (1) ì•„ì´í…œ ID ì°¾ê¸°\n",
    "        item_sql = text(\"SELECT id FROM market_items WHERE name = :name\")\n",
    "        item_id = conn.execute(item_sql, {\"name\": item_name}).scalar()\n",
    "        \n",
    "        if not item_id:\n",
    "            print(f\"âŒ '{item_name}' ì•„ì´í…œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return None, None\n",
    "\n",
    "        print(f\"ğŸ” '{item_name}' (ID: {item_id}) ë°ì´í„° ìˆ˜ì§‘ ì¤‘...\")\n",
    "\n",
    "        # (2) ê°€ê²© ë¡œê·¸ ê°€ì ¸ì˜¤ê¸° (ì»¬ëŸ¼ëª…: current_min_price, logged_at)\n",
    "        price_sql = text(\"\"\"\n",
    "            SELECT logged_at, current_min_price\n",
    "            FROM market_price_logs\n",
    "            WHERE item_id = :item_id\n",
    "            ORDER BY logged_at ASC\n",
    "        \"\"\")\n",
    "        df_prices = pd.read_sql(price_sql, conn, params={\"item_id\": item_id})\n",
    "        \n",
    "        # (3) GPT Score ê°€ì ¸ì˜¤ê¸° (ì»¬ëŸ¼ëª…: notice_date, gpt_score)\n",
    "        notice_sql = text(\"\"\"\n",
    "            SELECT r.notice_date, i.gpt_score\n",
    "            FROM item_notice_impacts i\n",
    "            JOIN raw_notices r ON i.notice_id = r.id\n",
    "            WHERE i.item_id = :item_id\n",
    "            ORDER BY r.notice_date ASC\n",
    "        \"\"\")\n",
    "        df_notices = pd.read_sql(notice_sql, conn, params={\"item_id\": item_id})\n",
    "        \n",
    "        print(f\"   - ê°€ê²© ë¡œê·¸: {len(df_prices)}ê°œ\")\n",
    "        print(f\"   - ê´€ë ¨ ê³µì§€: {len(df_notices)}ê°œ\")\n",
    "        \n",
    "        return df_prices, df_notices\n",
    "\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# [í…ŒìŠ¤íŠ¸] ì•„ì´í…œ ì´ë¦„ ì…ë ¥\n",
    "# ---------------------------------------------------------\n",
    "TARGET_ITEM = \"ìœ ë¬¼ ì›í•œ ê°ì¸ì„œ\"  # ğŸ‘ˆ ë¶„ì„í•˜ê³  ì‹¶ì€ ì•„ì´í…œ ì´ë¦„\n",
    "df_raw, df_gpt = get_item_data(TARGET_ITEM)\n",
    "\n",
    "display(df_raw.head())\n",
    "display(df_gpt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cc3d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "# =========================================================\n",
    "# [ì—…ê·¸ë ˆì´ë“œ] í•¨ìˆ˜ 1: ì›ë³¸ ì²­ì†Œ í›„ 30ë¶„ë´‰ ë§Œë“¤ê¸°\n",
    "# =========================================================\n",
    "def preprocess_ohlc_and_fill(df_raw):\n",
    "    print(\"ğŸ§¹ [1ë‹¨ê³„] Raw ë°ì´í„° ì •ì œ ë° 30ë¶„ë´‰ ë³€í™˜...\")\n",
    "    \n",
    "    df = df_raw.copy()\n",
    "    \n",
    "    # 1. ì¸ë±ìŠ¤ ì„¤ì • (í•„ìˆ˜)\n",
    "    if 'logged_at' in df.columns:\n",
    "        df['logged_at'] = pd.to_datetime(df['logged_at'])\n",
    "        df.set_index('logged_at', inplace=True)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # ğŸš¨ [í•µì‹¬ ì¶”ê°€] ì›ë³¸(10ë¶„ ë‹¨ìœ„) ë‹¨ê³„ì—ì„œ ì´ìƒì¹˜ 1ì°¨ ì œê±°\n",
    "    # -----------------------------------------------------\n",
    "    # 10ë¶„ ë°ì´í„°ì´ë¯€ë¡œ í•˜ë£¨(24ì‹œê°„)ë¥¼ ë³´ë ¤ë©´ windowê°€ ì•½ 144ê°œ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "    # (6ê°œ/ì‹œê°„ * 24ì‹œê°„ = 144)\n",
    "    raw_window = 432\n",
    "    raw_sigma = 7 # ì›ë³¸ì€ ë³€ë™ì„±ì´ ë” í¬ë‹ˆ 2.0ë³´ë‹¤ ì‚´ì§ ì—¬ìœ  ìˆê²Œ 2.5 ì¶”ì²œ\n",
    "    \n",
    "    # ì›ë³¸ ê°€ê²© ì»¬ëŸ¼: 'current_min_price'\n",
    "    rolling_mean = df['current_min_price'].rolling(window=raw_window, center=True).mean()\n",
    "    rolling_std = df['current_min_price'].rolling(window=raw_window, center=True).std()\n",
    "    \n",
    "    upper = rolling_mean + (raw_sigma * rolling_std)\n",
    "    lower = rolling_mean - (raw_sigma * rolling_std)\n",
    "    \n",
    "    outliers = (df['current_min_price'] > upper) | (df['current_min_price'] < lower)\n",
    "    cnt = outliers.sum()\n",
    "    \n",
    "    if cnt > 0:\n",
    "        print(f\"   âœ¨ ì›ë³¸ ë°ì´í„°ì—ì„œ {cnt}ê°œì˜ ì´ìƒì¹˜ë¥¼ ë¯¸ë¦¬ ì œê±°í–ˆìŠµë‹ˆë‹¤!\")\n",
    "        df.loc[outliers, 'current_min_price'] = np.nan\n",
    "        df['current_min_price'] = df['current_min_price'].interpolate(method='linear')\n",
    "    # -----------------------------------------------------\n",
    "    \n",
    "    # 2. 30ë¶„ ë‹¨ìœ„ Resampling (ì´ì œ ê¹¨ë—í•œ ì¬ë£Œë¡œ ìš”ë¦¬í•©ë‹ˆë‹¤)\n",
    "    df_resampled = df['current_min_price'].resample('30min').agg(['first', 'max', 'min', 'last', 'mean'])\n",
    "    df_resampled.columns = ['Open', 'High', 'Low', 'Close', 'Price_Mean']\n",
    "    \n",
    "    # 3. ë¹ˆì¹¸ ì±„ìš°ê¸°\n",
    "    df_filled = df_resampled.ffill().bfill()\n",
    "    \n",
    "    print(f\"   - ì •ì œ ì™„ë£Œ: {len(df_filled)}ê°œ êµ¬ê°„ (30ë¶„ë´‰)\")\n",
    "    return df_filled\n",
    "\n",
    "# =========================================================\n",
    "# [ì¶”ê°€ë¨] í•¨ìˆ˜ 1.5: ì´ìƒì¹˜ ì œê±° (Rolling Z-Score)\n",
    "# =========================================================\n",
    "def clean_outliers_rolling(df, column='Close', window=48, sigma=3):\n",
    "    print(f\"ğŸ§¼ [1.5ë‹¨ê³„] ì´ìƒì¹˜ ì œê±° ì¤‘... (Window={window}, Sigma={sigma})\")\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # ì´ë™ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°\n",
    "    rolling_mean = df_clean[column].rolling(window=window, center=True).mean()\n",
    "    rolling_std = df_clean[column].rolling(window=window, center=True).std()\n",
    "    \n",
    "    # ì´ìƒì¹˜ íŒë³„ ê¸°ì¤€\n",
    "    upper_bound = rolling_mean + (sigma * rolling_std)\n",
    "    lower_bound = rolling_mean - (sigma * rolling_std)\n",
    "    \n",
    "    # ì´ìƒì¹˜ ì¡°ê±´ í™•ì¸ ë° ê°œìˆ˜ ì¹´ìš´íŠ¸\n",
    "    outlier_mask = (df_clean[column] > upper_bound) | (df_clean[column] < lower_bound)\n",
    "    outlier_count = outlier_mask.sum()\n",
    "    \n",
    "    if outlier_count > 0:\n",
    "        print(f\"   ğŸš¨ {outlier_count}ê°œì˜ íŠ€ëŠ” ê°€ê²© ë°œê²¬! ë¶€ë“œëŸ½ê²Œ ë³´ì •í•©ë‹ˆë‹¤.\")\n",
    "        # ì´ìƒì¹˜ë¥¼ NaNìœ¼ë¡œ ë³€ê²½ í›„ ë³´ê°„(Interpolation)\n",
    "        df_clean.loc[outlier_mask, column] = np.nan\n",
    "        df_clean[column] = df_clean[column].interpolate(method='linear')\n",
    "    else:\n",
    "        print(\"   âœ… ë°ì´í„°ê°€ ì•„ì£¼ ê¹¨ë—í•©ë‹ˆë‹¤.\")\n",
    "        \n",
    "    return df_clean\n",
    "\n",
    "# =========================================================\n",
    "# í•¨ìˆ˜ 2: GPT ìŠ¤ì½”ì–´ ë§¤í•‘ (ë‚ ì§œ ê³„ì‚° ë¡œì§)\n",
    "# =========================================================\n",
    "def apply_gpt_scores(df_price, df_gpt):\n",
    "    print(\"ğŸ¤– [2ë‹¨ê³„] GPT ê³µì§€ì‚¬í•­ ì ìˆ˜ ë§¤í•‘ ì¤‘...\")\n",
    "    \n",
    "    df = df_price.copy()\n",
    "    df['GPT_Score'] = 0.0 # ê¸°ë³¸ê°’ 0\n",
    "    \n",
    "    if df_gpt is None or df_gpt.empty:\n",
    "        print(\"   - ê³µì§€ì‚¬í•­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ì ìˆ˜ 0ìœ¼ë¡œ ì§„í–‰)\")\n",
    "        return df\n",
    "\n",
    "    count = 0\n",
    "    for idx, row in df_gpt.iterrows():\n",
    "        notice_date = pd.to_datetime(row['notice_date'])\n",
    "        score = row['gpt_score']\n",
    "        \n",
    "        # [ê·œì¹™ ì ìš©] ê³µì§€ì¼ 10:00 ~ 7ì¼ ë’¤ 06:00\n",
    "        start_time = notice_date.replace(hour=10, minute=0, second=0)\n",
    "        end_time = (notice_date + timedelta(days=7)).replace(hour=6, minute=0, second=0)\n",
    "        \n",
    "        # í•´ë‹¹ ê¸°ê°„ ë§ˆìŠ¤í‚¹\n",
    "        mask = (df.index >= start_time) & (df.index < end_time)\n",
    "        \n",
    "        if mask.any():\n",
    "            df.loc[mask, 'GPT_Score'] = score\n",
    "            count += 1\n",
    "            \n",
    "    print(f\"   - ì´ {count}ê±´ì˜ ê³µì§€ì‚¬í•­ ì ìˆ˜ ë°˜ì˜ ì™„ë£Œ\")\n",
    "    return df\n",
    "\n",
    "# =========================================================\n",
    "# [ì‹¤í–‰] íŒŒì´í”„ë¼ì¸ ì—°ê²° (ìˆœì„œ ì¤‘ìš”!)\n",
    "# =========================================================\n",
    "\n",
    "# 1. ê°€ê²© ë°ì´í„° 1ì°¨ ì •ì œ (ë¹ˆì¹¸ ì±„ìš°ê¸°)\n",
    "df_temp = preprocess_ohlc_and_fill(df_raw)\n",
    "\n",
    "# 2. [ì¶”ê°€] ì´ìƒì¹˜ ì œê±° (ì—¬ê¸°ì„œ íŠ€ëŠ” ê°’ì„ ì¡ìŠµë‹ˆë‹¤!)\n",
    "df_clean_price = clean_outliers_rolling(df_temp, column='Price_Mean', window=48, sigma=3)\n",
    "\n",
    "# 3. GPT ì ìˆ˜ ê²°í•©\n",
    "df_final = apply_gpt_scores(df_clean_price, df_gpt)\n",
    "\n",
    "# 4. ê²°ê³¼ í™•ì¸\n",
    "print(\"-\" * 30)\n",
    "print(f\"ğŸ—“ï¸ ë°ì´í„° ê¸°ê°„: {df_final.index.min()} ~ {df_final.index.max()}\")\n",
    "print(\"-\" * 30)\n",
    "display(df_final.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef3d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ì‹œê°í™” (í™•ì¸ìš©)\n",
    "# ---------------------------------------------------------\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# ê°€ê²© ê·¸ë˜í”„ (íŒŒë€ìƒ‰)\n",
    "ax1 = plt.gca()\n",
    "ax1.plot(df_final.index, df_final['Price_Mean'], color='blue', label='Avg Price')\n",
    "ax1.set_ylabel('Price (Gold)')\n",
    "\n",
    "# GPT ì ìˆ˜ ê·¸ë˜í”„ (ë¹¨ê°„ìƒ‰, yì¶• ê³µìœ )\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(df_final.index, df_final['GPT_Score'], color='red', linestyle='--', alpha=0.5, label='GPT Score')\n",
    "ax2.set_ylabel('GPT Score')\n",
    "ax2.set_ylim(-1.5, 1.5)\n",
    "\n",
    "# 2. ëˆˆê¸ˆ í˜•ì‹: 'ì›”-ì¼' í˜•íƒœë¡œ ë³´ì—¬ì¤˜ë¼ (ì˜ˆ: 01-29)\n",
    "# ì—°ë„ê¹Œì§€ ë³´ê³  ì‹¶ìœ¼ë©´ '%Y-%m-%d'ë¡œ ë°”ê¾¸ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "ax1.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.WEDNESDAY, interval=1))\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "ax1.grid(True, which='major', axis='x', linestyle='--', alpha=0.5) # ìˆ˜ìš”ì¼ë§ˆë‹¤ ì„¸ë¡œ ì ì„  ì¶”ê°€\n",
    "\n",
    "plt.title(f\"[{TARGET_ITEM}] Price Trend vs GPT Score\")\n",
    "plt.show()\n",
    "\n",
    "# ë°ì´í„° í™•ì¸\n",
    "display(df_final.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70752a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. ì›ë³¸ ë³µì‚¬\n",
    "df_ml = df_final.copy()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. ê¸°ìˆ ì  ì§€í‘œ (ì´ë™í‰ê· , ë³€ë™ì„±, RSI)\n",
    "# ---------------------------------------------------------\n",
    "# ê°€ê²©ì˜ íë¦„(Trend)ì„ ëª¨ë¸ì—ê²Œ ì•Œë ¤ì¤ë‹ˆë‹¤.\n",
    "df_ml['MA_5'] = df_ml['Close'].rolling(window=5).mean()    # 2.5ì‹œê°„ í‰ê· \n",
    "df_ml['MA_48'] = df_ml['Close'].rolling(window=48).mean()  # 24ì‹œê°„(1ì¼) í‰ê· \n",
    "df_ml['Std_20'] = df_ml['Close'].rolling(window=20).std()  # ë³€ë™ì„±\n",
    "\n",
    "# RSI (ìƒëŒ€ê°•ë„ì§€ìˆ˜)\n",
    "delta = df_ml['Close'].diff()\n",
    "gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "rs = gain / loss\n",
    "df_ml['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. [í•µì‹¬] Lag Features (ì‹œì°¨ ë°ì´í„°)\n",
    "# ---------------------------------------------------------\n",
    "# ëª¨ë¸ í•™ìŠµìš©ìœ¼ë¡œ \"ê³¼ê±°ì˜ ì •ë‹µ\"ì„ ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘ëŠ” ê²ë‹ˆë‹¤.\n",
    "# (ë‚˜ì¤‘ì— ì˜ˆì¸¡í•  ë•ŒëŠ” ì´ ì»¬ëŸ¼ì„ ìš°ë¦¬ê°€ ì§ì ‘ ì±„ì›Œë„£ìœ¼ë©° ì˜ˆì¸¡í•´ì•¼ í•©ë‹ˆë‹¤)\n",
    "df_ml['Close_Lag1'] = df_ml['Close'].shift(1)  # 30ë¶„ ì „\n",
    "df_ml['Close_Lag2'] = df_ml['Close'].shift(2)  # 1ì‹œê°„ ì „\n",
    "df_ml['GPT_Lag1'] = df_ml['GPT_Score'].shift(1) # 30ë¶„ ì „ ê³µì§€ ì ìˆ˜\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. ì‹œê°„ ì •ë³´ (Time Features)\n",
    "# ---------------------------------------------------------\n",
    "# ë¯¸ë˜ì˜ ì‹œê°„(ìš”ì¼, ì‹œê°„)ì€ ìš°ë¦¬ê°€ ë‹¬ë ¥ë§Œ ë³´ë©´ 100% ì•Œ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•„ì£¼ ì¢‹ì€ íŒíŠ¸ì…ë‹ˆë‹¤.\n",
    "df_ml['Hour'] = df_ml.index.hour\n",
    "df_ml['DayOfWeek'] = df_ml.index.dayofweek # 0:ì›” ~ 6:ì¼\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. Target (ì •ë‹µì§€: ë‹¤ìŒ 30ë¶„ ë’¤ì˜ ê°€ê²©)\n",
    "# ---------------------------------------------------------\n",
    "df_ml['Target'] = df_ml['Close'].shift(-1)\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì œê±° (ì´ë™í‰ê·  ë“±ìœ¼ë¡œ ìƒê¸´ ì•ë¶€ë¶„ ë¹ˆì¹¸ ì‚­ì œ)\n",
    "df_ml = df_ml.dropna()\n",
    "\n",
    "print(f\"ğŸ“š ë¨¸ì‹ ëŸ¬ë‹ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {df_ml.shape}\")\n",
    "display(df_ml.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2367ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 1. í•™ìŠµ ë°ì´í„° ì¤€ë¹„ (ê·œì¹™: 2ì›” 4ì¼ 06:00 ì´ì „ë§Œ ì‚¬ìš©)\n",
    "# ---------------------------------------------------------\n",
    "# df_mlì€ ì´ë¯¸ ì •ì œ ë° í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ì´ ëë‚œ ë°ì´í„°ë¼ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
    "train_cutoff = pd.to_datetime(\"2026-02-04 06:00:00\")\n",
    "\n",
    "features = [\n",
    "    'MA_5', 'MA_48', 'Std_20', 'RSI',\n",
    "    'Close_Lag1', 'Close_Lag2', 'GPT_Lag1',\n",
    "    'Hour', 'DayOfWeek'\n",
    "]\n",
    "target = 'Target'\n",
    "\n",
    "# í•™ìŠµìš© ë°ì´í„° (Cutoff ì´ì „)\n",
    "X_train = df_ml[df_ml.index < train_cutoff][features]\n",
    "y_train = df_ml[df_ml.index < train_cutoff][target]\n",
    "\n",
    "# ê²€ì¦ìš© ë°ì´í„° (Cutoff ì´í›„ ~ í˜„ì¬) - ê³¼ì í•© ë°©ì§€ìš©\n",
    "X_valid = df_ml[df_ml.index >= train_cutoff][features]\n",
    "y_valid = df_ml[df_ml.index >= train_cutoff][target]\n",
    "\n",
    "print(f\"ğŸ“š XGB í•™ìŠµ ë°ì´í„°: {X_train.shape} ( ~ {train_cutoff})\")\n",
    "print(f\"ğŸ“ XGB ê²€ì¦ ë°ì´í„°: {X_valid.shape}\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. ëª¨ë¸ ì •ì˜ (LightGBM)\n",
    "# ---------------------------------------------------------\n",
    "print(\"âš¡ LightGBM í•™ìŠµ ì‹œì‘...\")\n",
    "\n",
    "model_lgbm = LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    force_col_wise=True,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. í•™ìŠµ\n",
    "# ---------------------------------------------------------\n",
    "model_lgbm.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    eval_metric='rmse',\n",
    "    callbacks=[]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5eb0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import timedelta\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. í•™ìŠµ ë°ì´í„° ì¤€ë¹„ (ê·œì¹™: 2ì›” 4ì¼ 06:00 ì´ì „ë§Œ ì‚¬ìš©)\n",
    "# ---------------------------------------------------------\n",
    "# df_mlì€ ì´ë¯¸ ì •ì œ ë° í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ì´ ëë‚œ ë°ì´í„°ë¼ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
    "train_cutoff = pd.to_datetime(\"2026-02-04 06:00:00\")\n",
    "\n",
    "features = [\n",
    "    'MA_5', 'MA_48', 'Std_20', 'RSI',\n",
    "    'Close_Lag1', 'Close_Lag2', 'GPT_Lag1',\n",
    "    'Hour', 'DayOfWeek'\n",
    "]\n",
    "target = 'Target'\n",
    "\n",
    "# í•™ìŠµìš© ë°ì´í„° (Cutoff ì´ì „)\n",
    "X_train = df_ml[df_ml.index < train_cutoff][features]\n",
    "y_train = df_ml[df_ml.index < train_cutoff][target]\n",
    "\n",
    "# ê²€ì¦ìš© ë°ì´í„° (Cutoff ì´í›„ ~ í˜„ì¬) - ê³¼ì í•© ë°©ì§€ìš©\n",
    "X_valid = df_ml[df_ml.index >= train_cutoff][features]\n",
    "y_valid = df_ml[df_ml.index >= train_cutoff][target]\n",
    "\n",
    "print(f\"ğŸ“š XGB í•™ìŠµ ë°ì´í„°: {X_train.shape} ( ~ {train_cutoff})\")\n",
    "print(f\"ğŸ“ XGB ê²€ì¦ ë°ì´í„°: {X_valid.shape}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. XGBoost ëª¨ë¸ í•™ìŠµ\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\nğŸ”¥ XGBoost í•™ìŠµ ì‹œì‘...\")\n",
    "model_xgb = xgb.XGBRegressor(\n",
    "    n_estimators=2000,       # í•™ìŠµ íšŸìˆ˜ (ë„‰ë„‰í•˜ê²Œ)\n",
    "    learning_rate=0.01,      # ì²œì²œíˆ ê¼¼ê¼¼í•˜ê²Œ\n",
    "    max_depth=6,             # ë‚˜ë¬´ ê¹Šì´\n",
    "    subsample=0.8,           # ë°ì´í„° ìƒ˜í”Œë§\n",
    "    colsample_bytree=0.8,    # ì»¬ëŸ¼ ìƒ˜í”Œë§\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    early_stopping_rounds=50 # 50ë²ˆ ë™ì•ˆ ì„±ëŠ¥ í–¥ìƒ ì—†ìœ¼ë©´ ë©ˆì¶¤\n",
    ")\n",
    "\n",
    "model_xgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    verbose=False  # ë¡œê·¸ ë„ˆë¬´ ë§ì´ ëœ¨ë©´ ì§€ì €ë¶„í•´ì„œ ê»ìŠµë‹ˆë‹¤\n",
    ")\n",
    "print(\"âœ… XGBoost í•™ìŠµ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619d6364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from neuralprophet import load\n",
    "import torch\n",
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet, save, set_random_seed\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„\n",
    "# ---------------------------------------------------------\n",
    "set_random_seed(42)\n",
    "\n",
    "# PyTorch ë³´ì•ˆ í•´ì œ (í•™ìŠµ ì‹œì—” í•„ìš” ì—†ì§€ë§Œ ìŠµê´€ì ìœ¼ë¡œ ë„£ì–´ë‘ë©´ ì•ˆì „)\n",
    "_original_torch_load = torch.load\n",
    "def patched_torch_load(*args, **kwargs):\n",
    "    if 'weights_only' not in kwargs:\n",
    "        kwargs['weights_only'] = False\n",
    "    return _original_torch_load(*args, **kwargs)\n",
    "torch.load = patched_torch_load\n",
    "\n",
    "# ë°ì´í„° ì¤€ë¹„ (ì˜¤ì „ 6ì‹œ ì´ì „)\n",
    "train_cutoff = pd.to_datetime(\"2026-02-04 06:00:00\")\n",
    "df_np = df_final.reset_index()[['logged_at', 'Close', 'GPT_Score']].copy()\n",
    "df_np.columns = ['ds', 'y', 'GPT_Score']\n",
    "df_train = df_np[df_np['ds'] < train_cutoff]\n",
    "\n",
    "print(\"âœ… NeuralProphetìš© ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\")\n",
    "display(df_np.tail())\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. ëª¨ë¸ ì •ì˜\n",
    "# ---------------------------------------------------------\n",
    "def NeuralProphet_fit(FORECAST_HORIZON):\n",
    "    m = NeuralProphet(\n",
    "        n_forecasts=FORECAST_HORIZON,\n",
    "        n_lags=240,\n",
    "        \n",
    "        n_changepoints=20,     # ì¢€ ë” ì„¸ë°€í•˜ê²Œ êº¾ì„ì„ ê°ì§€í•˜ë„ë¡ ëŠ˜ë¦¼\n",
    "        trend_reg=0.05,\n",
    "        weekly_seasonality=True, # ìˆ˜ìš”ì¼ ì ê²€ ë“±ì˜ ì£¼ê°„ íŒ¨í„´ í•™ìŠµ\n",
    "        daily_seasonality=True,  # ìƒˆë²½/ì €ë… íŒ¨í„´ í•™ìŠµ\n",
    "        yearly_seasonality=False,# 1ë…„ì¹˜ ë°ì´í„°ëŠ” ì•„ë‹ˆë¯€ë¡œ ë”\n",
    "        learning_rate=0.01,\n",
    "        growth='off'\n",
    "    )\n",
    "\n",
    "    # 3. GPT ì ìˆ˜(ê³µì§€ì‚¬í•­)ë¥¼ 'ë¯¸ë˜ë¥¼ ì•„ëŠ” ë³€ìˆ˜'ë¡œ ì¶”ê°€\n",
    "    # (ìš°ë¦¬ê°€ ë¯¸ë˜ ê³µì§€ì‚¬í•­ì€ ì—†ë‹¤ê³ (0) ê°€ì •í•˜ê³  ì…ë ¥í•  ê²ƒì´ê¸° ë•Œë¬¸)\n",
    "    m.add_future_regressor(\"GPT_Score\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3. ì¬í•™ìŠµ ë° ì €ì¥\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"ğŸ§  [3ì¼ ë‹¨ê¸° ì†ì„±ë°˜] ëª¨ë¸ í•™ìŠµ ì‹œì‘... (ëª©í‘œ: {FORECAST_HORIZON}ìŠ¤í…)\")\n",
    "\n",
    "    # í•™ìŠµ (ë³´ì•ˆ ì˜µì…˜ ì ìš©)\n",
    "    m.fit(df_train, freq=\"30min\", num_workers=0, checkpointing=False)\n",
    "\n",
    "    # ëª¨ë¸ ë®ì–´ì“°ê¸°\n",
    "    model_filename = \"lostark_price_model.np\"\n",
    "    save(m, model_filename)\n",
    "\n",
    "    print(f\"âœ… ìµœì í™”ëœ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_filename}\")\n",
    "    print(\"   ì´ì œ ì´ ëª¨ë¸ì€ '3ì¼ ë’¤'ê¹Œì§€ë§Œ ì˜ˆì¸¡í•˜ì§€ë§Œ, ê·¸ë§Œí¼ ë” ì •êµí•  ê²ë‹ˆë‹¤!\")\n",
    "\n",
    "FORECAST_HORIZON = 144\n",
    "# NeuralProphet_fit(FORECAST_HORIZON)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (Load)\n",
    "# ---------------------------------------------------------\n",
    "print(\"ğŸ“‚ [3ì¼ ì˜ˆì¸¡ ì „ìš©] ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...\")\n",
    "# ì•„ê¹Œ ì €ì¥í•œ íŒŒì¼ëª… (lostark_price_model.np)\n",
    "loaded_model = load(\"lostark_price_model.np\")\n",
    "print(\"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ! (í•™ìŠµ ê³¼ì • ì—†ì´ ë°”ë¡œ ì˜ˆì¸¡ ê°€ëŠ¥)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1902f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. í‰ê°€ í•¨ìˆ˜\n",
    "# ---------------------------------------------------------\n",
    "def get_ensemble_score(y_true, y_pred, name):\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_pred = np.array(y_pred).flatten()\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-7))) * 100\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    true_diff = np.diff(y_true)\n",
    "    pred_diff = np.diff(y_pred)\n",
    "    dir_acc = (np.sum(np.sign(true_diff) == np.sign(pred_diff)) / len(true_diff)) * 100\n",
    "    \n",
    "    print(f\"ğŸ“Š [{name:15}] MAE: {mae:7.2f} | DirAcc: {dir_acc:5.1f}% | R2: {r2:5.2f}\")\n",
    "    return mae\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. ëª¨ë¸ë³„ ì˜ˆì¸¡ ë°ì´í„° ìƒì„± (ì‹œê°„ì¶• ë™ê¸°í™”ìš©)\n",
    "# ---------------------------------------------------------\n",
    "cutoff = pd.to_datetime(\"2026-02-04 06:00:00\")\n",
    "eval_df = df_ml[df_ml.index >= cutoff].copy()\n",
    "\n",
    "# A. ML ëª¨ë¸ (LGBM, XGB)\n",
    "p_lgbm_series = pd.Series(model_lgbm.predict(eval_df[features]), index=eval_df.index)\n",
    "p_xgb_series = pd.Series(model_xgb.predict(eval_df[features]), index=eval_df.index)\n",
    "\n",
    "# B. NeuralProphet (ë¯¸ë¼ ì „ëµ ì ìš©)\n",
    "last_date = df_np['ds'].max()\n",
    "future_dates = pd.date_range(start=last_date + pd.Timedelta(minutes=30), periods=144, freq='30min')\n",
    "df_dummy = pd.DataFrame({'ds': future_dates, 'y': np.nan, 'GPT_Score': 0.0})\n",
    "df_extended = pd.concat([df_np, df_dummy], ignore_index=True)\n",
    "\n",
    "forecast_np = loaded_model.predict(df_extended)\n",
    "mask_np = (forecast_np['ds'] >= cutoff) & (forecast_np['ds'] <= last_date)\n",
    "df_np_valid = forecast_np[mask_np].copy().dropna(subset=['y', 'yhat1'])\n",
    "\n",
    "# [ìˆ˜ì • í¬ì¸íŠ¸] ì¸ë±ìŠ¤ ì´ë¦„ì„ df_np_valid['ds']ë¡œ ì •í™•íˆ ë§¤ì¹­\n",
    "p_np_series = pd.Series(df_np_valid['yhat1'].values, index=df_np_valid['ds'])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ë°ì´í„° íƒ€ì„ë¼ì¸ í†µí•© (Intersection)\n",
    "# ---------------------------------------------------------\n",
    "combined = pd.DataFrame({\n",
    "    'actual': eval_df[target],\n",
    "    'lgbm': p_lgbm_series,\n",
    "    'xgb': p_xgb_series,\n",
    "    'np': p_np_series\n",
    "}).dropna()\n",
    "\n",
    "print(f\"âœ… ìµœì¢… ì•™ìƒë¸” ë¶„ì„ ìƒ˜í”Œ ìˆ˜: {len(combined)}ê°œ\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. ìµœì¢… ê²°ê³¼ ì¶œë ¥ (ê°€ì¤‘ì¹˜ 0.55 : 0.35 : 0.10)\n",
    "# ---------------------------------------------------------\n",
    "if not combined.empty:\n",
    "    y_true = combined['actual'].values\n",
    "    p_lgbm = combined['lgbm'].values\n",
    "    p_xgb = combined['xgb'].values\n",
    "    p_np = combined['np'].values\n",
    "    \n",
    "    # ì•™ìƒë¸” ê³„ì‚°\n",
    "    p_ensemble = (p_lgbm * 0.4) + (p_xgb * 0.4) + (p_np * 0.2)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"ğŸ† AI ì•™ìƒë¸” ìµœì¢… ì„±ì í‘œ (ê²€ì¦ê¸°ê°„: 2/4 06:00 ~ í˜„ì¬)\")\n",
    "    print(\"=\"*70)\n",
    "    get_ensemble_score(y_true, p_lgbm, \"LightGBM\")\n",
    "    get_ensemble_score(y_true, p_xgb, \"XGBoost\")\n",
    "    get_ensemble_score(y_true, p_np, \"NeuralProphet\")\n",
    "    print(\"-\" * 70)\n",
    "    get_ensemble_score(y_true, p_ensemble, \"TOTAL ENSEMBLE\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # ê·¸ë˜í”„ ì‹œê°í™”\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(combined.index, y_true, label='Actual Price', color='black', alpha=0.3, linewidth=2)\n",
    "    plt.plot(combined.index, p_ensemble, label='AI Ensemble Prediction', color='red', linewidth=2)\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))\n",
    "    plt.title(\"Final Ensemble Analysis: Actual vs Prediction\", fontsize=15)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.2)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"âŒ ë°ì´í„° í†µí•© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. combined ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8c421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ì•™ìƒë¸” ê³„ì‚°\n",
    "p_ensemble = (combined['lgbm'] * 0.4) + (combined['xgb'] * 0.4) + (combined['np'] * 0.2)\n",
    "\n",
    "# ì„±ì  ê³„ì‚° í•¨ìˆ˜\n",
    "def print_final_report(y_true, y_pred, name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-7))) * 100\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    true_diff = np.diff(y_true)\n",
    "    pred_diff = np.diff(y_pred)\n",
    "    dir_acc = (np.sum(np.sign(true_diff) == np.sign(pred_diff)) / len(true_diff)) * 100\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"ğŸ† [{name} ì„±ì í‘œ]\")\n",
    "    print(f\"   - RMSE: {rmse:.2f}\")\n",
    "    print(f\"   - MAE : {mae:.2f}\")\n",
    "    print(f\"   - MAPE: {mape:.2f}%\")\n",
    "    print(f\"   - r2  : {r2:.2f}\")\n",
    "    print(f\"   - Dir Acc: {dir_acc:.1f}%\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# ì¶œë ¥ ì‹¤í–‰\n",
    "print_final_report(combined['actual'], p_ensemble, \"âœ¨ 3ëŒ€ì¥ ì•™ìƒë¸” (ìµœì¢…)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
